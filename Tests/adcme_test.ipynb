{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Cannot load /home/darve/adncat/.julia/packages/ADCME/OGm7w/deps/CustomOps/build/libadcme.so. Please recompile the shared library by `ADCME.precompile()` for using custom operators.\n",
      "└ @ ADCME /home/darve/adncat/.julia/packages/ADCME/OGm7w/src/ADCME.jl:76\n"
     ]
    }
   ],
   "source": [
    "using ADCME\n",
    "using Plots\n",
    "using PyCall\n",
    "#### Read data\n",
    "py\"\"\"\n",
    "import numpy as np\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_falloff (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f_hi(a, T, R)\n",
    "        v1 = (a[:,2] + a[:,3] * T + a[:,4] * T^2 + a[:,5] * T^3 + a[:,6] * T^4) * R\n",
    "        v2 = (a[:,2] + a[:,3] * T / 2 + a[:,4] * T^2 /3 + a[:,5] * T^3 /4 + a[:,6] * T^4 /5 + a[:,7]/T) * R * T\n",
    "        v3 = (a[:,2] * log(T) + a[:,3] * T + a[:,4] * T^2 /2 + a[:,5] * T^3 /3 + a[:,6] * T^4 / 4 + a[:,8]) * R\n",
    "    return [v1 v2 v3]\n",
    "end\n",
    " \n",
    "function f_lo(a, T, R)\n",
    "    v1 = (a[:,9] + a[:,10] * T + a[:,11] * T^2 + a[:,12] * T^3 + a[:,13] * T^4) * R\n",
    "    v2 = (a[:,9] + a[:,10] * T / 2 + a[:,11] * T^2 /3 + a[:,12] * T^3 /4 + a[:,13] * T^4 /5 + a[:,14]/T) * R * T\n",
    "    v3 = (a[:,9] * log(T) + a[:,10] * T + a[:,11] * T^2 /2 + a[:,12] * T^3 /3 + a[:,13] * T^4 / 4 + a[:,15]) * R\n",
    "    return [v1 v2 v3]\n",
    "end \n",
    "\n",
    "function compute_falloff(T, pr, a)\n",
    "    fcent = (1 - a[1]) * exp(-T/a[2]) + a[1] * exp(-T/a[3]) + exp(-a[4]/T)\n",
    "    c = -0.4 - 0.67 * log(fcent) / log(10)\n",
    "    n = 0.75 - 1.27 * log(fcent) / log(10)\n",
    "    f1 = (log(pr) / log(10) + c) / (n - 0.14 *(log(pr) / log(10) + c))\n",
    "    return  10 ^ ((log(fcent) / log(10)) / (1 + f1 ^ 2))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 1  # Volume\n",
    "m = (py\"np.load\"(\"data/density.npy\"))[1]  # Total mass\n",
    "tbd = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/tbd.npy\") .+ 1\n",
    "falofr = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/falofr.npy\") .+ 1\n",
    "elmr = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/elmr.npy\") .+ 1\n",
    "NASA_coeffs = py\"np.load\"(\"data/NASA_coeffs.npy\")\n",
    "W = py\"np.load\"(\"data/molecular_weights.npy\") # Molar weight\n",
    "ν1 = py\"np.load\"(\"data/reactants_stoich_coeffs.npy\") # Forward molar stoichiometric coefficients\n",
    "ν2 = py\"np.load\"(\"data/product_stoich_coeffs.npy\") # Backward model stoichiometric coefficients\n",
    "reversible = py\"np.load\"(\"data/reversible.npy\")\n",
    "N = size(ν1)[1]  # Number of Species\n",
    "M = size(ν1)[2]  # Number of Reactions\n",
    "ν1_order = zeros(N,M)\n",
    "ν = ν2 - ν1  \n",
    "pa = 100000 # 1 bar\n",
    "R = 8314.4621 # Gas constant in kmol\n",
    "### Constants: Combustion Chamber Level\n",
    "min_dot = 0 # Rate at which mass enters the chamber\n",
    "mout_dot = 0 # Rate at which mass leaves the chamber\n",
    "Yin = ones(N) # Mass fraction of species entering the chamber\n",
    "Yout = ones(N) # Mass fraction of species leaving the chamber\n",
    "Qdot = 0 # Heating source\n",
    "m_dot = min_dot - mout_dot\n",
    "hin = 1 # Enthalpy of input\n",
    "### Unknowns\n",
    "Tt_cant = py\"np.load\"(\"data/temperature.npy\")\n",
    "T = Tt_cant[1] # Temperature\n",
    "Y = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/ini_mass_fraction.npy\") # Mass fractions\n",
    "#Y .+= 0.00001\n",
    "#Y ./ sum(Y)\n",
    "### Quantities that depend on the Unknowns\n",
    "tbd = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/tbd.npy\") .+ 1\n",
    "tbd = Int.(tbd)\n",
    "falofr = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/falofr.npy\") .+ 1\n",
    "falofr = Int.(falofr)\n",
    "elmr = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/elmr.npy\") .+ 1\n",
    "elmr = Int.(elmr)\n",
    "\n",
    "order = py\"np.load\"(\"data/reaction_orders.npy\")\n",
    "Af = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/pre_exponential_factor.npy\") # preexponential constant Afj\n",
    "β = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/temperature_exponent.npy\") # Temperature exponent\n",
    "E = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/activation_energy.npy\") # Activation energy for the reactions in kJ\n",
    "\n",
    "order_t = py\"np.load\"(\"data/reaction_orders_t.npy\")\n",
    "efficiency_t = py\"np.load\"(\"data/efficiency_t.npy\")\n",
    "Af_t = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/pre_exponential_factor_t.npy\") # preexponential constant Afj\n",
    "β_t = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/temperature_exponent_t.npy\") # Temperature exponent\n",
    "E_t = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/activation_energy_t.npy\") # Activation energy for the reactions in kJ\n",
    "\n",
    "order_f = py\"np.load\"(\"data/reaction_orders_f.npy\")\n",
    "troefall = py\"np.load\"(\"data/troefall.npy\") .+ 1\n",
    "troefall_coeff = py\"np.load\"(\"data/troefall_coeff.npy\")\n",
    "efficiency_f = py\"np.load\"(\"data/efficiency_f.npy\")\n",
    "Af_hi = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/pre_exponential_factor_hi.npy\") # preexponential constant Afj\n",
    "β_hi = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/temperature_exponent_hi.npy\") # Temperature exponent\n",
    "E_hi = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/activation_energy_hi.npy\") \n",
    "\n",
    "Af_lo = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/pre_exponential_factor_lo.npy\") # preexponential constant Afj\n",
    "β_lo = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/temperature_exponent_lo.npy\") # Temperature exponent\n",
    "E_lo = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/activation_energy_lo.npy\") \n",
    "\n",
    "ν1_order[:,elmr] = order\n",
    "ν1_order[:,tbd] = order_t\n",
    "ν1_order[:,falofr] = order_f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function q(t)\n",
    "    t0 = 1e-5\n",
    "    r = 1e-6\n",
    "    c = 1e12\n",
    "    return c * exp(-(t-t0)^2 / r^2)\n",
    "end\n",
    "function f(TY, Qdot, t)\n",
    "    T = TY[1]\n",
    "    Y = TY[2:end]\n",
    "    ρ = m / V # density\n",
    "    X = tf.reshape(ρ * tf.divide(Y, W), (N,1)) # Concentration\n",
    "    Q = ADCME.constant(ones(M)) # Individual progress rates\n",
    "    islarge = T > ADCME.constant(NASA_coeffs[:,1])\n",
    "    islarge = convert_to_tensor(islarge, dtype=Float64)\n",
    "    fhi = f_hi(NASA_coeffs, T, R)\n",
    "    flo = f_lo(NASA_coeffs, T, R)\n",
    "    cp = islarge .* fhi[:,1] + (1 - islarge) .* flo[:,1]\n",
    "    h = islarge .* fhi[:,2] + (1 - islarge) .* flo[:,2]\n",
    "    s = islarge .* fhi[:,3] + (1 - islarge) .* flo[:,3]\n",
    "    cvk = cp .- R\n",
    "    ΔS = ν' * s  # Entropy change for reaction j\n",
    "    ΔH = ν' * h # Entahlpy change for reaction j\n",
    "    ####\n",
    "    M_t = efficiency_t' * X[:,1]\n",
    "    Kf_t = Af_t .* (T ^ β_t) .* exp(-E_t / (R * T)) .* M_t\n",
    "    Kr_t = Kf_t ./ (((pa/(R * T)) ^ sum(ν[:,tbd], dims=1)')[:,1] .* exp(ΔS[tbd] ./ R - ΔH[tbd] / (R * T)))\n",
    "    Qtbd =  Kf_t .* (prod(tf.pow(X, order_t), dims=1)) .- Kr_t .* (prod(tf.pow(X, ν2[:,tbd]), dims=1) .* reversible[tbd])\n",
    "    M_f = efficiency_f' * X[:,1]\n",
    "    Kf_lo = Af_lo .* (T ^ β_lo) .* exp(-E_lo / (R * T)) .* M_f\n",
    "    Kf_hi = Af_hi .* (T ^ β_hi) .* exp(-E_hi / (R * T)) \n",
    "    Pr = Kf_lo ./ Kf_hi\n",
    "    Fac = ADCME.constant(ones(size(falofr)[1]))\n",
    "    for (i,s) in enumerate(troefall)\n",
    "        a = troefall_coeff[:,i]\n",
    "        fcent = (1 - a[1]) * exp(-T/a[2]) + a[1] * exp(-T/a[3]) + exp(-a[4]/T)\n",
    "        c = -0.4 - 0.67 * log(fcent) / log(10)\n",
    "        n = 0.75 - 1.27 * log(fcent) / log(10)\n",
    "        f1 = (log(Pr[s]) / log(10) + c) / (n - 0.14 *(log(Pr[s]) / log(10) + c))\n",
    "        Fac = scatter_update(Fac, troefall[i], 10 ^ ((log(fcent) / log(10)) / (1 + f1 ^ 2)))\n",
    "    end\n",
    "    Kf_f = Kf_lo ./ (1 .+ (Kf_lo ./ Kf_hi)) .* Fac\n",
    "    Kr_f = Kf_f ./ (((pa/(R * T)) ^ sum(ν[:,falofr], dims=1)')[:,1] .* exp(ΔS[falofr] ./ R - ΔH[falofr] / (R * T)))\n",
    "    Qfalofr = Kf_f .* (prod(tf.pow(X, order_f), dims=1)) .- Kr_f .* (prod(tf.pow(X, ν2[:,falofr]), dims=1) .* reversible[falofr])\n",
    "    ####\n",
    "#     Af = exp(θ[:,1])\n",
    "#     β = zeros(M)\n",
    "#     E = exp(θ[:,3])\n",
    "    Kf = Af .* (T ^ β) .* exp(-E / (R * T))\n",
    "    Kr = Kf ./ (((pa/(R * T)) ^ sum(ν[:,elmr], dims=1)')[:,1] .* exp(ΔS[elmr] ./ R - ΔH[elmr] / (R * T)))\n",
    "    Qelmr = Kf .* (prod(tf.pow(X, order), dims=1)) .- Kr .* (prod(tf.pow(X, ν2[:,elmr]), dims=1) .* reversible[elmr])\n",
    "    Q = [Qtbd' Qfalofr' Qelmr']\n",
    "    ν_new = [ν[:,tbd] ν[:,falofr] ν[:,elmr]]\n",
    "    ##### Computing ω_dot \n",
    "    cv = sum(cvk ./ W .* Y) # Mass heat capacities\n",
    "    u = h / W - R ./ W * T   # Internal energy for species\n",
    "    p = sum(X) * R * T # pressure\n",
    "    ω_dot = W .* sum(ν_new .* Q, dims=2)\n",
    "    ###### Species Conservation\n",
    "    mgen_dot = V * ω_dot\n",
    "    Y_dot = (1 / m) * ((min_dot * (Yin - Y) - mout_dot * Y) + mgen_dot) \n",
    "    ###### EnergyConservation\n",
    "    #Qdot = abs(fc(t * 1e5, [20,20,1], theta[2]) + 1) * 10 ^ theta[1] \n",
    "    #Qdot = theta[1] * 1e11 * exp(-(t * 1e5 - theta[2]) ^ 2 / (0.01))\n",
    "    T_dot = 1 / (m * cv) * (Qdot + min_dot * (hin - sum(u .* Yin)) - p * V / m * mout_dot - sum(mgen_dot .* u))\n",
    "    return tf.concat([tf.reshape(T_dot, (1,)), Y_dot], 0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001×7 Array{Float64,2}:\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0   0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "    ⋮                                                 ⋮          \n",
       " 3052.05  0.00010655   0.322755  0.0971676  0.360445  0.0528594  0.166667\n",
       " 3051.97  0.000106253  0.322781  0.0971562  0.360524  0.0527666  0.166667\n",
       " 3051.9   0.000105957  0.322806  0.0971448  0.360602  0.052674   0.166667\n",
       " 3051.82  0.000105662  0.322832  0.0971335  0.360681  0.0525818  0.166667\n",
       " 3051.75  0.000105368  0.322857  0.0971222  0.360759  0.0524897  0.166667\n",
       " 3051.67  0.000105075  0.322882  0.097111   0.360837  0.052398   0.166667\n",
       " 3051.6   0.000104784  0.322907  0.0970998  0.360915  0.0523064  0.166667\n",
       " 3051.52  0.000104493  0.322933  0.0970886  0.360992  0.0522152  0.166667\n",
       " 3051.45  0.000104203  0.322958  0.0970774  0.36107   0.0521242  0.166667\n",
       " 3051.37  0.000103914  0.322983  0.0970663  0.361147  0.0520334  0.166667\n",
       " 3051.3   0.000103627  0.323008  0.0970552  0.361224  0.0519429  0.166667\n",
       " 3051.23  0.00010334   0.323032  0.0970442  0.361301  0.0518527  0.166667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/timestep.npy\")\n",
    "Tt_cant = py\"np.load\"(\"data/temperature.npy\")\n",
    "T_ref = zeros(size(timestep)[1])\n",
    "T_ref[2:end] = Tt_cant\n",
    "T_ref[1] = 500\n",
    "Yt_cant = py\"np.load\"(\"data/mass_fraction.npy\")\n",
    "Y_ref = [Y Yt_cant]\n",
    "obs = [T_ref Y_ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Afr = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/pre_exponential_factor.npy\") # preexponential constant Afj\n",
    "βr = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/temperature_exponent.npy\") # Temperature exponent\n",
    "Er = py\"np.load\"(\"/home/darve/adncat/yizhou/PSAAP3/Tests/data/activation_energy.npy\") # Activation energy for the reactions in kJ\n",
    "pr = [log.(Afr) βr log.(Er)]\n",
    "pr[1,1] = 28.25\n",
    "pr[2,1] = 17.75\n",
    "pr[1,3] = 18.75\n",
    "pr[2,3] = 17.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-29 18:31:52.154831: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n",
      "2020-11-29 18:31:52.168361: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2600020000 Hz\n",
      "2020-11-29 18:31:52.173179: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9660ba0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-29 18:31:52.173249: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-11-29 18:31:52.182905: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/darve/adncat/.conda/envs/my_root/lib/libfabric:/home/darve/adncat/.conda/envs/my_root/lib:/opt/ohpc/pub/compiler/gcc/7.3.0/lib64:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/compiler/lib/intel64:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/compiler/lib/intel64_lin:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mpi/intel64/lib:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mpi/mic/lib:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/ipp/lib/intel64:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/mkl/lib/intel64_lin:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/tbb/lib/intel64/gcc4.1:/opt/ohpc/pub/compiler/intel-18/debugger_2018/iga/lib:/opt/ohpc/pub/compiler/intel-18/debugger_2018/libipt/intel64/lib:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/daal/lib/intel64_lin:/opt/ohpc/pub/compiler/intel-18/compilers_and_libraries_2018.2.199/linux/daal/../tbb/lib/intel64_lin/gcc4.4\n",
      "2020-11-29 18:31:52.182936: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-11-29 18:31:52.182974: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (compute-5-11): /proc/driver/nvidia/version does not exist\n",
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME /home/darve/adncat/.julia/packages/ADCME/OGm7w/src/optim.jl:326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, current loss=6.646854521041674e6\n",
      "iter 1, current loss=3.381582029827431e7\n",
      "iter 2, current loss=5.159849989300523e6\n",
      "================ STEP 0 ===============\n",
      "iter 3, current loss=6.736370998417625e6\n",
      "iter 4, current loss=4.959655856624292e6\n",
      "================ STEP 1 ===============\n",
      "iter 5, current loss=1.1668425327305902e7\n",
      "iter 6, current loss=4.896404733653325e6\n",
      "================ STEP 2 ===============\n",
      "iter 7, current loss=8.677565506217524e6\n",
      "iter 8, current loss=4.840176520436827e6\n",
      "================ STEP 3 ===============\n",
      "iter 9, current loss=4.767682301942314e6\n",
      "iter 10, current loss=4.365517560201789e6\n",
      "iter 11, current loss=1.1874225984513797e7\n",
      "iter 12, current loss=4.327434192118552e6\n",
      "iter 13, current loss=2.2295885968180854e7\n",
      "iter 14, current loss=4.1730791211482394e6\n",
      "iter 15, current loss=4.216649727657601e6\n",
      "iter 16, current loss=4.0606183441615077e6\n",
      "================ STEP 4 ===============\n",
      "iter 17, current loss=3.0722159615308635e7\n",
      "iter 18, current loss=4.057888656048855e6\n",
      "iter 19, current loss=4.0447945593485907e6\n",
      "iter 20, current loss=4.0305972182883034e6\n",
      "================ STEP 5 ===============\n",
      "iter 21, current loss=4.344408372487163e6\n",
      "iter 22, current loss=3.926008988881019e6\n",
      "================ STEP 6 ===============\n",
      "iter 23, current loss=3.9216567415467505e6\n",
      "================ STEP 7 ===============\n",
      "iter 24, current loss=3.9187981488161525e6\n",
      "================ STEP 8 ===============\n",
      "iter 25, current loss=3.9183666462133117e6\n",
      "================ STEP 9 ===============\n",
      "iter 26, current loss=3.9151339285195144e6\n",
      "================ STEP 10 ===============\n",
      "iter 27, current loss=3.9087409552472318e6\n",
      "================ STEP 11 ===============\n",
      "iter 28, current loss=3.895167644380763e6\n",
      "================ STEP 12 ===============\n",
      "iter 29, current loss=3.854678323867057e6\n",
      "================ STEP 13 ===============\n",
      "iter 30, current loss=3.779747160328157e6\n",
      "================ STEP 14 ===============\n",
      "iter 31, current loss=3.6344917264769236e6\n",
      "================ STEP 15 ===============\n",
      "iter 32, current loss=3.133181629396832e6\n",
      "================ STEP 16 ===============\n",
      "iter 33, current loss=1.065209369371567e7\n",
      "iter 34, current loss=1.8565900578356568e7\n",
      "iter 35, current loss=3.1088969249908747e6\n",
      "iter 36, current loss=3.052566372368767e6\n",
      "================ STEP 17 ===============\n",
      "iter 37, current loss=4.072360654768426e6\n",
      "iter 38, current loss=3.0368048810482956e6\n",
      "================ STEP 18 ===============\n",
      "iter 39, current loss=3.0036968239054745e6\n",
      "================ STEP 19 ===============\n",
      "iter 40, current loss=3.000118856725756e6\n",
      "================ STEP 20 ===============\n",
      "iter 41, current loss=2.999296289803216e6\n",
      "================ STEP 21 ===============\n",
      "iter 42, current loss=2.999166138771628e6\n",
      "iter 43, current loss=2.9986742083345903e6\n",
      "================ STEP 22 ===============\n",
      "iter 44, current loss=2.991238489032203e6\n",
      "================ STEP 23 ===============\n",
      "iter 45, current loss=2.9825550172855137e6\n",
      "================ STEP 24 ===============\n",
      "iter 46, current loss=2.950245971713686e6\n",
      "================ STEP 25 ===============\n",
      "iter 47, current loss=2.9142747471580077e6\n",
      "================ STEP 26 ===============\n",
      "iter 48, current loss=2.8833181572020957e6\n",
      "================ STEP 27 ===============\n",
      "iter 49, current loss=2.8075090053175353e6\n",
      "iter 50, current loss=2.801573740748787e6\n",
      "================ STEP 28 ===============\n",
      "iter 51, current loss=2.7290107652245522e6\n",
      "================ STEP 29 ===============\n",
      "iter 52, current loss=2.844430683449587e6\n",
      "iter 53, current loss=2.7139970671146363e6\n",
      "================ STEP 30 ===============\n",
      "iter 54, current loss=2.624904635087478e6\n",
      "================ STEP 31 ===============\n",
      "iter 55, current loss=2.570320677553488e6\n",
      "================ STEP 32 ===============\n",
      "iter 56, current loss=2.5516088918943545e6\n",
      "================ STEP 33 ===============\n",
      "iter 57, current loss=2.5417439386387365e6\n",
      "================ STEP 34 ===============\n",
      "iter 58, current loss=2.5370297331222007e6\n",
      "================ STEP 35 ===============\n",
      "iter 59, current loss=2.5337204316678094e6\n",
      "================ STEP 36 ===============\n",
      "iter 60, current loss=2.5297456204626164e6\n",
      "================ STEP 37 ===============\n",
      "iter 61, current loss=2.528742588641033e6\n",
      "================ STEP 38 ===============\n",
      "iter 62, current loss=2.528654674646333e6\n",
      "================ STEP 39 ===============\n",
      "iter 63, current loss=2.528477390399275e6\n",
      "================ STEP 40 ===============\n",
      "iter 64, current loss=2.5280720912308074e6\n",
      "================ STEP 41 ===============\n",
      "iter 65, current loss=2.52736665478047e6\n",
      "================ STEP 42 ===============\n",
      "iter 66, current loss=2.5238875779271442e6\n",
      "================ STEP 43 ===============\n",
      "iter 67, current loss=2.519107412489253e6\n",
      "================ STEP 44 ===============\n",
      "iter 68, current loss=2.5146560193769597e6\n",
      "iter 69, current loss=2.5105392542263344e6\n",
      "================ STEP 45 ===============\n",
      "iter 70, current loss=2.489797912038481e6\n",
      "================ STEP 46 ===============\n",
      "iter 71, current loss=2.9215906443931484e6\n",
      "iter 72, current loss=2.482230353676093e6\n",
      "================ STEP 47 ===============\n",
      "iter 73, current loss=2.576692049577109e6\n",
      "iter 74, current loss=2.4616215692175366e6\n",
      "================ STEP 48 ===============\n",
      "iter 75, current loss=2.427517641201713e6\n",
      "================ STEP 49 ===============\n",
      "iter 76, current loss=2.34082802839547e6\n",
      "================ STEP 50 ===============\n",
      "iter 77, current loss=5.007573276092207e6\n",
      "iter 78, current loss=2.332853027419504e6\n",
      "================ STEP 51 ===============\n",
      "iter 79, current loss=2.568323558791904e6\n",
      "iter 80, current loss=2.3181253763659513e6\n",
      "================ STEP 52 ===============\n",
      "iter 81, current loss=2.34111933830738e6\n",
      "iter 82, current loss=2.312702124260745e6\n",
      "================ STEP 53 ===============\n",
      "iter 83, current loss=2.3169975840304997e6\n",
      "iter 84, current loss=2.310934322827399e6\n",
      "================ STEP 54 ===============\n",
      "iter 85, current loss=2.3107540166880176e6\n",
      "iter 86, current loss=2.3101751624935186e6\n",
      "================ STEP 55 ===============\n",
      "iter 87, current loss=2.3083515298792934e6\n",
      "================ STEP 56 ===============\n",
      "iter 88, current loss=2.2915399439457213e6\n",
      "================ STEP 57 ===============\n",
      "iter 89, current loss=2.2668475044609606e6\n",
      "================ STEP 58 ===============\n",
      "iter 90, current loss=2.193990570369233e6\n",
      "================ STEP 59 ===============\n",
      "iter 91, current loss=2.5875610269769114e6\n",
      "iter 92, current loss=2.182498314178824e6\n",
      "================ STEP 60 ===============\n",
      "iter 93, current loss=2.175454921138299e6\n",
      "iter 94, current loss=2.155426185645034e6\n",
      "================ STEP 61 ===============\n",
      "iter 95, current loss=2.134098918272276e6\n",
      "================ STEP 62 ===============\n",
      "iter 96, current loss=2.133903760328221e6\n",
      "iter 97, current loss=2.1314772347406745e6\n",
      "================ STEP 63 ===============\n",
      "iter 98, current loss=2.1284878020027196e6\n",
      "================ STEP 64 ===============\n",
      "iter 99, current loss=2.1278181016539847e6\n",
      "================ STEP 65 ===============\n",
      "iter 100, current loss=2.126219929418197e6\n",
      "================ STEP 66 ===============\n",
      "iter 101, current loss=2.1232703368758773e6\n",
      "================ STEP 67 ===============\n",
      "iter 102, current loss=2.10679906292338e6\n",
      "================ STEP 68 ===============\n",
      "iter 103, current loss=2.0991695181780625e6\n",
      "================ STEP 69 ===============\n",
      "iter 104, current loss=2.0928792264692509e6\n",
      "iter 105, current loss=2.0848615779054274e6\n",
      "================ STEP 70 ===============\n",
      "iter 106, current loss=2.102980028737666e6\n",
      "iter 107, current loss=2.0781160079503455e6\n",
      "================ STEP 71 ===============\n",
      "iter 108, current loss=2.0722732572697038e6\n",
      "================ STEP 72 ===============\n",
      "iter 109, current loss=2.0590490554475305e6\n",
      "iter 110, current loss=2.0571967451262926e6\n",
      "================ STEP 73 ===============\n",
      "iter 111, current loss=2.0479707906525568e6\n",
      "iter 112, current loss=2.043174150002257e6\n",
      "================ STEP 74 ===============\n",
      "iter 113, current loss=2.1237805378543986e6\n",
      "iter 114, current loss=2.0195128857598407e6\n",
      "================ STEP 75 ===============\n",
      "iter 115, current loss=2.1237482262642784e6\n",
      "iter 116, current loss=1.9950400127167208e6\n",
      "================ STEP 76 ===============\n",
      "iter 117, current loss=2.0116661146661248e6\n",
      "iter 118, current loss=1.982419128919804e6\n",
      "================ STEP 77 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 119, current loss=1.975523081006335e6\n",
      "================ STEP 78 ===============\n",
      "iter 120, current loss=1.9708857159141912e6\n",
      "================ STEP 79 ===============\n",
      "iter 121, current loss=1.9674784250350823e6\n",
      "================ STEP 80 ===============\n",
      "iter 122, current loss=1.9649375588754653e6\n",
      "================ STEP 81 ===============\n",
      "iter 123, current loss=1.9627739214461925e6\n",
      "================ STEP 82 ===============\n",
      "iter 124, current loss=1.9597764900807333e6\n",
      "================ STEP 83 ===============\n",
      "iter 125, current loss=1.9582794455834744e6\n",
      "================ STEP 84 ===============\n",
      "iter 126, current loss=1.9551768229408674e6\n",
      "================ STEP 85 ===============\n",
      "iter 127, current loss=1.9405342826720076e6\n",
      "================ STEP 86 ===============\n",
      "iter 128, current loss=2.02278605763837e6\n",
      "iter 129, current loss=1.9304197896954368e6\n",
      "================ STEP 87 ===============\n",
      "iter 130, current loss=2.364388715607216e6\n",
      "iter 131, current loss=1.9236606658799727e6\n",
      "================ STEP 88 ===============\n",
      "iter 132, current loss=2.200940229395281e6\n",
      "iter 133, current loss=1.9066028769159787e6\n",
      "================ STEP 89 ===============\n",
      "iter 134, current loss=2.237169915459661e6\n",
      "iter 135, current loss=1.8837450565520169e6\n",
      "================ STEP 90 ===============\n",
      "iter 136, current loss=1.8480892814472555e6\n",
      "iter 137, current loss=1.8345330442748677e6\n",
      "================ STEP 91 ===============\n",
      "iter 138, current loss=1.8451405946523412e6\n",
      "iter 139, current loss=1.80128285596888e6\n",
      "================ STEP 92 ===============\n",
      "iter 140, current loss=3.892870613784153e6\n",
      "iter 141, current loss=1.7651325455657612e6\n",
      "================ STEP 93 ===============\n",
      "iter 142, current loss=1.888440500673664e6\n",
      "iter 143, current loss=1.6783433236358627e6\n",
      "================ STEP 94 ===============\n",
      "iter 144, current loss=1.3318685726458363e6\n",
      "================ STEP 95 ===============\n",
      "iter 145, current loss=2.888765482814584e6\n",
      "iter 146, current loss=1.3252410769424126e6\n",
      "================ STEP 96 ===============\n",
      "iter 147, current loss=1.3193057979962123e6\n",
      "================ STEP 97 ===============\n",
      "iter 148, current loss=1.319011641066854e6\n",
      "================ STEP 98 ===============\n",
      "iter 149, current loss=1.305496773319319e6\n",
      "================ STEP 99 ===============\n",
      "iter 150, current loss=1.3010315658173917e6\n",
      "================ STEP 100 ===============\n",
      "iter 151, current loss=1.2931294823693112e6\n",
      "================ STEP 101 ===============\n",
      "iter 152, current loss=1.2947952693903372e6\n",
      "iter 153, current loss=1.2817877946123444e6\n",
      "================ STEP 102 ===============\n",
      "iter 154, current loss=1.2796420133471e6\n",
      "================ STEP 103 ===============\n",
      "iter 155, current loss=1.2739888801599536e6\n",
      "================ STEP 104 ===============\n",
      "iter 156, current loss=1.2689499659121374e6\n",
      "================ STEP 105 ===============\n",
      "iter 157, current loss=1.263525224703995e6\n",
      "================ STEP 106 ===============\n",
      "iter 158, current loss=1.257330980233685e6\n",
      "================ STEP 107 ===============\n",
      "iter 159, current loss=1.2187502919889367e6\n",
      "================ STEP 108 ===============\n",
      "iter 160, current loss=3.893170430402541e6\n",
      "iter 161, current loss=1.202354243807279e6\n",
      "================ STEP 109 ===============\n",
      "iter 162, current loss=4.352713250877621e6\n",
      "iter 163, current loss=1.1716908198188525e6\n",
      "================ STEP 110 ===============\n",
      "iter 164, current loss=1.4342698771926286e6\n",
      "iter 165, current loss=1.1249713972744881e6\n",
      "================ STEP 111 ===============\n",
      "iter 166, current loss=1.2176060812579433e6\n",
      "iter 167, current loss=1.0882195141708243e6\n",
      "================ STEP 112 ===============\n",
      "iter 168, current loss=1.1530229614700987e6\n",
      "iter 169, current loss=1.06420093064124e6\n",
      "================ STEP 113 ===============\n",
      "iter 170, current loss=1.184045444929603e6\n",
      "iter 171, current loss=1.0382519930870156e6\n",
      "================ STEP 114 ===============\n",
      "iter 172, current loss=1.2853409136525602e6\n",
      "iter 173, current loss=1.0171837343556171e6\n",
      "================ STEP 115 ===============\n",
      "iter 174, current loss=1.0360023278534007e6\n",
      "iter 175, current loss=996484.0796235758\n",
      "================ STEP 116 ===============\n",
      "iter 176, current loss=968762.4800892631\n",
      "================ STEP 117 ===============\n",
      "iter 177, current loss=947777.1465048471\n",
      "================ STEP 118 ===============\n",
      "iter 178, current loss=936383.4005567941\n",
      "================ STEP 119 ===============\n",
      "iter 179, current loss=919411.3481263861\n",
      "================ STEP 120 ===============\n",
      "iter 180, current loss=895514.6791316438\n",
      "================ STEP 121 ===============\n",
      "iter 181, current loss=873519.0807457869\n",
      "================ STEP 122 ===============\n",
      "iter 182, current loss=868456.0288358324\n",
      "================ STEP 123 ===============\n",
      "iter 183, current loss=866412.3090425681\n",
      "================ STEP 124 ===============\n",
      "iter 184, current loss=864414.2304604622\n",
      "================ STEP 125 ===============\n",
      "iter 185, current loss=861969.7872552016\n",
      "================ STEP 126 ===============\n",
      "iter 186, current loss=869844.8089131644\n",
      "iter 187, current loss=861535.2902771742\n",
      "================ STEP 127 ===============\n",
      "iter 188, current loss=861348.825913547\n",
      "================ STEP 128 ===============\n",
      "iter 189, current loss=861201.4462672563\n",
      "================ STEP 129 ===============\n",
      "iter 190, current loss=860926.7226247564\n",
      "================ STEP 130 ===============\n",
      "iter 191, current loss=860605.2629672831\n",
      "================ STEP 131 ===============\n",
      "iter 192, current loss=859767.73418012\n",
      "================ STEP 132 ===============\n",
      "iter 193, current loss=856769.920307539\n",
      "================ STEP 133 ===============\n",
      "iter 194, current loss=850310.6153061434\n",
      "================ STEP 134 ===============\n",
      "iter 195, current loss=837229.731447613\n",
      "================ STEP 135 ===============\n",
      "iter 196, current loss=882356.8669575531\n",
      "iter 197, current loss=834467.6854059035\n",
      "================ STEP 136 ===============\n",
      "iter 198, current loss=825887.3223486936\n",
      "================ STEP 137 ===============\n",
      "iter 199, current loss=849868.7760054115\n",
      "iter 200, current loss=823273.985121082\n",
      "================ STEP 138 ===============\n",
      "iter 201, current loss=811213.2295368378\n",
      "================ STEP 139 ===============\n",
      "iter 202, current loss=806248.9960064292\n",
      "================ STEP 140 ===============\n",
      "iter 203, current loss=805296.3971975091\n",
      "================ STEP 141 ===============\n",
      "iter 204, current loss=805082.174544624\n",
      "================ STEP 142 ===============\n",
      "iter 205, current loss=805031.9009917295\n",
      "================ STEP 143 ===============\n",
      "iter 206, current loss=804867.0701662425\n",
      "================ STEP 144 ===============\n",
      "iter 207, current loss=804657.1064357465\n",
      "================ STEP 145 ===============\n",
      "iter 208, current loss=803964.4796337958\n",
      "================ STEP 146 ===============\n",
      "iter 209, current loss=803583.8554729258\n",
      "================ STEP 147 ===============\n",
      "iter 210, current loss=803362.3068113141\n",
      "================ STEP 148 ===============\n",
      "iter 211, current loss=803222.2695716883\n",
      "================ STEP 149 ===============\n",
      "iter 212, current loss=802979.7361443992\n",
      "================ STEP 150 ===============\n",
      "iter 213, current loss=802536.8196861837\n",
      "================ STEP 151 ===============\n",
      "iter 214, current loss=801391.5123437729\n",
      "================ STEP 152 ===============\n",
      "iter 215, current loss=800224.6940301189\n",
      "================ STEP 153 ===============\n",
      "iter 216, current loss=794697.702451983\n",
      "================ STEP 154 ===============\n",
      "iter 217, current loss=787771.6573056437\n",
      "================ STEP 155 ===============\n",
      "iter 218, current loss=781704.3414870171\n",
      "================ STEP 156 ===============\n",
      "iter 219, current loss=772889.7331341062\n",
      "================ STEP 157 ===============\n",
      "iter 220, current loss=770500.413538783\n",
      "================ STEP 158 ===============\n",
      "iter 221, current loss=768737.5382491818\n",
      "================ STEP 159 ===============\n",
      "iter 222, current loss=767686.6703269095\n",
      "================ STEP 160 ===============\n",
      "iter 223, current loss=768296.8433394455\n",
      "iter 224, current loss=767224.0889272636\n",
      "================ STEP 161 ===============\n",
      "iter 225, current loss=768225.8658707666\n",
      "iter 226, current loss=766330.2460378679\n",
      "================ STEP 162 ===============\n",
      "iter 227, current loss=766001.5528889984\n",
      "================ STEP 163 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 228, current loss=765869.792321787\n",
      "================ STEP 164 ===============\n",
      "iter 229, current loss=765743.5219663468\n",
      "================ STEP 165 ===============\n",
      "iter 230, current loss=765448.3328523191\n",
      "================ STEP 166 ===============\n",
      "iter 231, current loss=764165.9350257475\n",
      "================ STEP 167 ===============\n",
      "iter 232, current loss=761641.8879622268\n",
      "================ STEP 168 ===============\n",
      "iter 233, current loss=757696.5992919835\n",
      "================ STEP 169 ===============\n",
      "iter 234, current loss=813665.8186894553\n",
      "iter 235, current loss=757177.8610066529\n",
      "================ STEP 170 ===============\n",
      "iter 236, current loss=755253.4426629582\n",
      "================ STEP 171 ===============\n",
      "iter 237, current loss=754387.0856426083\n",
      "================ STEP 172 ===============\n",
      "iter 238, current loss=753870.877126585\n",
      "================ STEP 173 ===============\n",
      "iter 239, current loss=753655.832570117\n",
      "================ STEP 174 ===============\n",
      "iter 240, current loss=750893.4490212351\n",
      "================ STEP 175 ===============\n",
      "iter 241, current loss=744991.9228733551\n",
      "================ STEP 176 ===============\n",
      "iter 242, current loss=738439.3427726354\n",
      "================ STEP 177 ===============\n",
      "iter 243, current loss=715672.715569629\n",
      "================ STEP 178 ===============\n",
      "iter 244, current loss=726792.2940680846\n",
      "iter 245, current loss=708212.2308244081\n",
      "================ STEP 179 ===============\n",
      "iter 246, current loss=709930.238559905\n",
      "iter 247, current loss=698555.5129023949\n",
      "================ STEP 180 ===============\n",
      "iter 248, current loss=691648.3121421608\n",
      "================ STEP 181 ===============\n",
      "iter 249, current loss=682942.1680446961\n",
      "================ STEP 182 ===============\n",
      "iter 250, current loss=669814.6121732513\n",
      "================ STEP 183 ===============\n",
      "iter 251, current loss=1.4470870500250806e6\n",
      "iter 252, current loss=669231.9622826756\n",
      "================ STEP 184 ===============\n",
      "iter 253, current loss=795059.6299244247\n",
      "iter 254, current loss=665204.571330402\n",
      "================ STEP 185 ===============\n",
      "iter 255, current loss=701246.0971047522\n",
      "iter 256, current loss=661423.3451434872\n",
      "================ STEP 186 ===============\n",
      "iter 257, current loss=653483.3742382611\n",
      "================ STEP 187 ===============\n",
      "iter 258, current loss=641018.24072155\n",
      "================ STEP 188 ===============\n",
      "iter 259, current loss=670594.3909394648\n",
      "iter 260, current loss=634692.6498341648\n",
      "================ STEP 189 ===============\n",
      "iter 261, current loss=754592.9461481727\n",
      "iter 262, current loss=631382.5081235584\n",
      "================ STEP 190 ===============\n",
      "iter 263, current loss=710942.3136085157\n",
      "iter 264, current loss=623851.3607506522\n",
      "================ STEP 191 ===============\n",
      "iter 265, current loss=613264.5040805173\n",
      "================ STEP 192 ===============\n",
      "iter 266, current loss=614800.0876378762\n",
      "iter 267, current loss=610630.2502952942\n",
      "================ STEP 193 ===============\n",
      "iter 268, current loss=607487.4930081374\n",
      "================ STEP 194 ===============\n",
      "iter 269, current loss=607079.5972306066\n",
      "================ STEP 195 ===============\n",
      "iter 270, current loss=601214.8286857475\n",
      "================ STEP 196 ===============\n",
      "iter 271, current loss=598634.0191891061\n",
      "================ STEP 197 ===============\n",
      "iter 272, current loss=596544.5139053361\n",
      "================ STEP 198 ===============\n",
      "iter 273, current loss=593634.8102445635\n",
      "================ STEP 199 ===============\n",
      "iter 274, current loss=589912.6921873502\n",
      "================ STEP 200 ===============\n",
      "iter 275, current loss=582389.3893464805\n",
      "================ STEP 201 ===============\n",
      "iter 276, current loss=576243.3992158828\n",
      "================ STEP 202 ===============\n",
      "iter 277, current loss=637341.7616491923\n",
      "iter 278, current loss=573807.4796242529\n",
      "================ STEP 203 ===============\n",
      "iter 279, current loss=572340.7979931571\n",
      "================ STEP 204 ===============\n",
      "iter 280, current loss=571887.5729415177\n",
      "================ STEP 205 ===============\n",
      "iter 281, current loss=571732.8194144152\n",
      "================ STEP 206 ===============\n",
      "iter 282, current loss=571499.631439981\n",
      "================ STEP 207 ===============\n",
      "iter 283, current loss=571082.8481460712\n",
      "================ STEP 208 ===============\n",
      "iter 284, current loss=567911.8285094511\n",
      "================ STEP 209 ===============\n",
      "iter 285, current loss=564220.5432616335\n",
      "================ STEP 210 ===============\n",
      "iter 286, current loss=559267.0522435072\n",
      "================ STEP 211 ===============\n",
      "iter 287, current loss=670716.0567784017\n",
      "iter 288, current loss=552173.4865046939\n",
      "================ STEP 212 ===============\n",
      "iter 289, current loss=529629.5142777713\n",
      "================ STEP 213 ===============\n",
      "iter 290, current loss=916654.5339273836\n",
      "iter 291, current loss=501779.0545421491\n",
      "================ STEP 214 ===============\n",
      "iter 292, current loss=1.5284278903367943e6\n",
      "iter 293, current loss=498521.440612506\n",
      "================ STEP 215 ===============\n",
      "iter 294, current loss=510038.8699905132\n",
      "iter 295, current loss=491351.29697848344\n",
      "================ STEP 216 ===============\n",
      "iter 296, current loss=482873.09218064183\n",
      "================ STEP 217 ===============\n",
      "iter 297, current loss=481336.1454493584\n",
      "================ STEP 218 ===============\n",
      "iter 298, current loss=477573.2097820174\n",
      "================ STEP 219 ===============\n",
      "iter 299, current loss=476351.9939933431\n",
      "================ STEP 220 ===============\n",
      "iter 300, current loss=494478.76359895535\n",
      "iter 301, current loss=475790.57640768535\n",
      "================ STEP 221 ===============\n",
      "iter 302, current loss=474342.17406315345\n",
      "================ STEP 222 ===============\n",
      "iter 303, current loss=470134.06425624643\n",
      "================ STEP 223 ===============\n",
      "iter 304, current loss=464664.64385695604\n",
      "================ STEP 224 ===============\n",
      "iter 305, current loss=456295.79778333614\n",
      "================ STEP 225 ===============\n",
      "iter 306, current loss=461755.9394140189\n",
      "iter 307, current loss=452214.010210856\n",
      "================ STEP 226 ===============\n",
      "iter 308, current loss=447730.21624123596\n",
      "================ STEP 227 ===============\n",
      "iter 309, current loss=446666.98338393756\n",
      "================ STEP 228 ===============\n",
      "iter 310, current loss=445349.68984821107\n",
      "================ STEP 229 ===============\n",
      "iter 311, current loss=442849.1124038546\n",
      "================ STEP 230 ===============\n",
      "iter 312, current loss=437837.5788071746\n",
      "================ STEP 231 ===============\n",
      "iter 313, current loss=426347.56552753097\n",
      "================ STEP 232 ===============\n",
      "iter 314, current loss=423060.24651822285\n",
      "================ STEP 233 ===============\n",
      "iter 315, current loss=417579.9453756419\n",
      "================ STEP 234 ===============\n",
      "iter 316, current loss=415405.6135416534\n",
      "================ STEP 235 ===============\n",
      "iter 317, current loss=409961.45368695876\n",
      "================ STEP 236 ===============\n",
      "iter 318, current loss=404749.10223138635\n",
      "================ STEP 237 ===============\n",
      "iter 319, current loss=412768.082260699\n",
      "iter 320, current loss=400276.1026432421\n",
      "================ STEP 238 ===============\n",
      "iter 321, current loss=391712.26494280144\n",
      "================ STEP 239 ===============\n",
      "iter 322, current loss=392798.4127459596\n",
      "iter 323, current loss=383500.64668193285\n",
      "================ STEP 240 ===============\n",
      "iter 324, current loss=372082.41844906483\n",
      "================ STEP 241 ===============\n",
      "iter 325, current loss=367016.35364993976\n",
      "================ STEP 242 ===============\n",
      "iter 326, current loss=375144.04402797064\n",
      "iter 327, current loss=365190.3011388895\n",
      "================ STEP 243 ===============\n",
      "iter 328, current loss=363797.35479224834\n",
      "================ STEP 244 ===============\n",
      "iter 329, current loss=356819.11223470425\n",
      "================ STEP 245 ===============\n",
      "iter 330, current loss=352357.2865037741\n",
      "================ STEP 246 ===============\n",
      "iter 331, current loss=348763.14394013875\n",
      "================ STEP 247 ===============\n",
      "iter 332, current loss=345559.9436691273\n",
      "================ STEP 248 ===============\n",
      "iter 333, current loss=347491.67490315175\n",
      "iter 334, current loss=326822.1274408392\n",
      "================ STEP 249 ===============\n",
      "iter 335, current loss=306218.6667002714\n",
      "================ STEP 250 ===============\n",
      "iter 336, current loss=295445.9749201817\n",
      "================ STEP 251 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 337, current loss=313436.90217876656\n",
      "iter 338, current loss=290381.82427533367\n",
      "================ STEP 252 ===============\n",
      "iter 339, current loss=280120.8248849994\n",
      "================ STEP 253 ===============\n",
      "iter 340, current loss=269713.24651526066\n",
      "================ STEP 254 ===============\n",
      "iter 341, current loss=247196.0970862512\n",
      "================ STEP 255 ===============\n",
      "iter 342, current loss=243216.91439787028\n",
      "iter 343, current loss=232089.03438278247\n",
      "================ STEP 256 ===============\n",
      "iter 344, current loss=1.1744380615411736e6\n",
      "iter 345, current loss=226777.23523767496\n",
      "iter 346, current loss=216848.05192324205\n",
      "================ STEP 257 ===============\n",
      "iter 347, current loss=206683.76779383013\n",
      "================ STEP 258 ===============\n",
      "iter 348, current loss=198701.27550432686\n",
      "================ STEP 259 ===============\n",
      "iter 349, current loss=189571.29002014198\n",
      "================ STEP 260 ===============\n",
      "iter 350, current loss=171248.41530256261\n",
      "================ STEP 261 ===============\n",
      "iter 351, current loss=178101.49284028055\n",
      "iter 352, current loss=167054.9761644672\n",
      "================ STEP 262 ===============\n",
      "iter 353, current loss=163970.07191945275\n",
      "================ STEP 263 ===============\n",
      "iter 354, current loss=156601.64284719195\n",
      "================ STEP 264 ===============\n",
      "iter 355, current loss=151290.79961864842\n",
      "================ STEP 265 ===============\n",
      "iter 356, current loss=146563.11201359835\n",
      "================ STEP 266 ===============\n",
      "iter 357, current loss=141318.55616914522\n",
      "================ STEP 267 ===============\n",
      "iter 358, current loss=138591.6376449051\n",
      "================ STEP 268 ===============\n",
      "iter 359, current loss=135511.0160546916\n",
      "================ STEP 269 ===============\n",
      "iter 360, current loss=131822.17499364426\n",
      "================ STEP 270 ===============\n",
      "iter 361, current loss=127791.82022507596\n",
      "================ STEP 271 ===============\n",
      "iter 362, current loss=123841.33779986804\n",
      "================ STEP 272 ===============\n",
      "iter 363, current loss=120820.54399665266\n",
      "================ STEP 273 ===============\n",
      "iter 364, current loss=119271.52743801461\n",
      "================ STEP 274 ===============\n",
      "iter 365, current loss=117550.1624608272\n",
      "================ STEP 275 ===============\n",
      "iter 366, current loss=113878.87883642613\n",
      "================ STEP 276 ===============\n",
      "iter 367, current loss=124666.26796291994\n",
      "iter 368, current loss=113497.49837719073\n",
      "================ STEP 277 ===============\n",
      "iter 369, current loss=112165.45732373316\n",
      "================ STEP 278 ===============\n",
      "iter 370, current loss=111685.55263026475\n",
      "================ STEP 279 ===============\n",
      "iter 371, current loss=111479.36225645538\n",
      "================ STEP 280 ===============\n",
      "iter 372, current loss=111358.86291304718\n",
      "================ STEP 281 ===============\n",
      "iter 373, current loss=111299.93456473041\n",
      "================ STEP 282 ===============\n",
      "iter 374, current loss=111270.85120450261\n",
      "================ STEP 283 ===============\n",
      "iter 375, current loss=111239.14658627234\n",
      "================ STEP 284 ===============\n",
      "iter 376, current loss=111182.53401667264\n",
      "================ STEP 285 ===============\n",
      "iter 377, current loss=111102.6943333977\n",
      "================ STEP 286 ===============\n",
      "iter 378, current loss=110829.95822925234\n",
      "================ STEP 287 ===============\n",
      "iter 379, current loss=110374.49786389587\n",
      "================ STEP 288 ===============\n",
      "iter 380, current loss=108438.07536487031\n",
      "================ STEP 289 ===============\n",
      "iter 381, current loss=106708.54379643154\n",
      "================ STEP 290 ===============\n",
      "iter 382, current loss=103701.96414530274\n",
      "================ STEP 291 ===============\n",
      "iter 383, current loss=103920.50560802943\n",
      "iter 384, current loss=103037.25498061808\n",
      "================ STEP 292 ===============\n",
      "iter 385, current loss=103411.0810684312\n",
      "iter 386, current loss=102730.87329695185\n",
      "================ STEP 293 ===============\n",
      "iter 387, current loss=102121.06114910179\n",
      "================ STEP 294 ===============\n",
      "iter 388, current loss=100810.28776332065\n",
      "================ STEP 295 ===============\n",
      "iter 389, current loss=99799.74177803248\n",
      "================ STEP 296 ===============\n",
      "iter 390, current loss=97196.46041257624\n",
      "================ STEP 297 ===============\n",
      "iter 391, current loss=93123.26466163881\n",
      "================ STEP 298 ===============\n",
      "iter 392, current loss=85519.7167239271\n",
      "================ STEP 299 ===============\n",
      "iter 393, current loss=264807.2103006094\n",
      "iter 394, current loss=84790.53197869395\n",
      "================ STEP 300 ===============\n",
      "iter 395, current loss=107155.18122652028\n",
      "iter 396, current loss=82968.20584137194\n",
      "================ STEP 301 ===============\n",
      "iter 397, current loss=80599.6173715487\n",
      "================ STEP 302 ===============\n",
      "iter 398, current loss=79327.75137986595\n",
      "================ STEP 303 ===============\n",
      "iter 399, current loss=81477.65056148765\n",
      "iter 400, current loss=78386.3107755341\n",
      "================ STEP 304 ===============\n",
      "iter 401, current loss=76448.24336058594\n",
      "================ STEP 305 ===============\n",
      "iter 402, current loss=79959.45714562843\n",
      "iter 403, current loss=75648.74452104003\n",
      "================ STEP 306 ===============\n",
      "iter 404, current loss=74329.29539760735\n",
      "================ STEP 307 ===============\n",
      "iter 405, current loss=72521.5880489363\n",
      "================ STEP 308 ===============\n",
      "iter 406, current loss=70601.40097121717\n",
      "================ STEP 309 ===============\n",
      "iter 407, current loss=71075.76637522006\n",
      "iter 408, current loss=69730.20929157874\n",
      "================ STEP 310 ===============\n",
      "iter 409, current loss=68577.46069360143\n",
      "================ STEP 311 ===============\n",
      "iter 410, current loss=67715.70062209517\n",
      "================ STEP 312 ===============\n",
      "iter 411, current loss=66550.71796412855\n",
      "================ STEP 313 ===============\n",
      "iter 412, current loss=65894.61418266718\n",
      "================ STEP 314 ===============\n",
      "iter 413, current loss=65459.49512308031\n",
      "================ STEP 315 ===============\n",
      "iter 414, current loss=65306.218310257944\n",
      "================ STEP 316 ===============\n",
      "iter 415, current loss=115385.12902330265\n",
      "iter 416, current loss=65196.31259263678\n",
      "================ STEP 317 ===============\n",
      "iter 417, current loss=64963.17000152242\n",
      "================ STEP 318 ===============\n",
      "iter 418, current loss=64700.287333026055\n",
      "================ STEP 319 ===============\n",
      "iter 419, current loss=64618.8058787565\n",
      "================ STEP 320 ===============\n",
      "iter 420, current loss=64509.37077143576\n",
      "================ STEP 321 ===============\n",
      "iter 421, current loss=64344.03393828783\n",
      "================ STEP 322 ===============\n",
      "iter 422, current loss=63982.78846761292\n",
      "================ STEP 323 ===============\n",
      "iter 423, current loss=63351.474363153786\n",
      "================ STEP 324 ===============\n",
      "iter 424, current loss=62924.8568076244\n",
      "================ STEP 325 ===============\n",
      "iter 425, current loss=67418.61536772398\n",
      "iter 426, current loss=62653.86339319803\n",
      "================ STEP 326 ===============\n",
      "iter 427, current loss=62392.65397617953\n",
      "================ STEP 327 ===============\n",
      "iter 428, current loss=61949.07708510764\n",
      "================ STEP 328 ===============\n",
      "iter 429, current loss=61668.647506061\n",
      "================ STEP 329 ===============\n",
      "iter 430, current loss=63366.83447006444\n",
      "iter 431, current loss=61566.482082449\n",
      "================ STEP 330 ===============\n",
      "iter 432, current loss=61123.44921756895\n",
      "================ STEP 331 ===============\n",
      "iter 433, current loss=60994.59176449188\n",
      "================ STEP 332 ===============\n",
      "iter 434, current loss=60837.33467720797\n",
      "================ STEP 333 ===============\n",
      "iter 435, current loss=60782.169046686446\n",
      "================ STEP 334 ===============\n",
      "iter 436, current loss=60726.107438671745\n",
      "================ STEP 335 ===============\n",
      "iter 437, current loss=60731.93329756355\n",
      "iter 438, current loss=60677.61642019373\n",
      "================ STEP 336 ===============\n",
      "iter 439, current loss=60576.79959149168\n",
      "================ STEP 337 ===============\n",
      "iter 440, current loss=60382.22326322527\n",
      "================ STEP 338 ===============\n",
      "iter 441, current loss=60120.52011026985\n",
      "================ STEP 339 ===============\n",
      "iter 442, current loss=59483.063562068324\n",
      "================ STEP 340 ===============\n",
      "iter 443, current loss=58298.574627272596\n",
      "================ STEP 341 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 444, current loss=56876.26711403746\n",
      "================ STEP 342 ===============\n",
      "iter 445, current loss=55513.42044112754\n",
      "================ STEP 343 ===============\n",
      "iter 446, current loss=54021.075860241384\n",
      "================ STEP 344 ===============\n",
      "iter 447, current loss=53322.785400825145\n",
      "iter 448, current loss=52768.621889567505\n",
      "================ STEP 345 ===============\n",
      "iter 449, current loss=50720.80458854779\n",
      "================ STEP 346 ===============\n",
      "iter 450, current loss=67397.74648966985\n",
      "iter 451, current loss=50363.331441903865\n",
      "================ STEP 347 ===============\n",
      "iter 452, current loss=50091.23299945978\n",
      "================ STEP 348 ===============\n",
      "iter 453, current loss=49085.684674696226\n",
      "================ STEP 349 ===============\n",
      "iter 454, current loss=48672.10651199404\n",
      "================ STEP 350 ===============\n",
      "iter 455, current loss=47380.30984901487\n",
      "================ STEP 351 ===============\n",
      "iter 456, current loss=45194.3534089749\n",
      "================ STEP 352 ===============\n",
      "iter 457, current loss=42781.265283450135\n",
      "================ STEP 353 ===============\n",
      "iter 458, current loss=40473.046773905444\n",
      "================ STEP 354 ===============\n",
      "iter 459, current loss=98804.38658567336\n",
      "iter 460, current loss=40215.03042151222\n",
      "================ STEP 355 ===============\n",
      "iter 461, current loss=39232.19433123304\n",
      "================ STEP 356 ===============\n",
      "iter 462, current loss=38858.91209787759\n",
      "================ STEP 357 ===============\n",
      "iter 463, current loss=38728.82353125989\n",
      "================ STEP 358 ===============\n",
      "iter 464, current loss=37954.33255935876\n",
      "================ STEP 359 ===============\n",
      "iter 465, current loss=37274.19989035154\n",
      "================ STEP 360 ===============\n",
      "iter 466, current loss=36122.77277711548\n",
      "================ STEP 361 ===============\n",
      "iter 467, current loss=35235.61630006217\n",
      "================ STEP 362 ===============\n",
      "iter 468, current loss=34902.76979353449\n",
      "================ STEP 363 ===============\n",
      "iter 469, current loss=34205.23719045742\n",
      "================ STEP 364 ===============\n",
      "iter 470, current loss=33875.04051885511\n",
      "================ STEP 365 ===============\n",
      "iter 471, current loss=33517.5004822609\n",
      "================ STEP 366 ===============\n",
      "iter 472, current loss=37027.3706114375\n",
      "iter 473, current loss=33346.30811767405\n",
      "================ STEP 367 ===============\n",
      "iter 474, current loss=32891.49692434278\n",
      "================ STEP 368 ===============\n",
      "iter 475, current loss=32112.608756527618\n",
      "================ STEP 369 ===============\n",
      "iter 476, current loss=37471.30999707189\n",
      "iter 477, current loss=32015.220251336174\n",
      "================ STEP 370 ===============\n",
      "iter 478, current loss=31793.860474390596\n",
      "================ STEP 371 ===============\n",
      "iter 479, current loss=31150.037945749333\n",
      "================ STEP 372 ===============\n",
      "iter 480, current loss=31071.244370303844\n",
      "================ STEP 373 ===============\n",
      "iter 481, current loss=30681.351840272502\n",
      "================ STEP 374 ===============\n",
      "iter 482, current loss=30454.531152403695\n",
      "================ STEP 375 ===============\n",
      "iter 483, current loss=30103.188243992743\n",
      "================ STEP 376 ===============\n",
      "iter 484, current loss=29537.142446425372\n",
      "================ STEP 377 ===============\n",
      "iter 485, current loss=59689.10463286833\n",
      "iter 486, current loss=29335.19636184019\n",
      "================ STEP 378 ===============\n",
      "iter 487, current loss=28603.52019179994\n",
      "================ STEP 379 ===============\n",
      "iter 488, current loss=28072.57996972985\n",
      "================ STEP 380 ===============\n",
      "iter 489, current loss=28728.559063531284\n",
      "iter 490, current loss=27921.239162416117\n",
      "================ STEP 381 ===============\n",
      "iter 491, current loss=27540.79280401312\n",
      "================ STEP 382 ===============\n",
      "iter 492, current loss=27229.785444521473\n",
      "================ STEP 383 ===============\n",
      "iter 493, current loss=27060.295615477356\n",
      "================ STEP 384 ===============\n",
      "iter 494, current loss=26860.785554217713\n",
      "================ STEP 385 ===============\n",
      "iter 495, current loss=26775.705461808255\n",
      "================ STEP 386 ===============\n",
      "iter 496, current loss=26560.416389908525\n",
      "================ STEP 387 ===============\n",
      "iter 497, current loss=26423.83721781326\n",
      "================ STEP 388 ===============\n",
      "iter 498, current loss=26289.83759040668\n",
      "================ STEP 389 ===============\n",
      "iter 499, current loss=26204.635914790117\n",
      "================ STEP 390 ===============\n",
      "iter 500, current loss=26414.485136549458\n",
      "iter 501, current loss=26171.849915811552\n",
      "================ STEP 391 ===============\n",
      "iter 502, current loss=26138.940966263497\n",
      "================ STEP 392 ===============\n",
      "iter 503, current loss=26121.733845874067\n",
      "================ STEP 393 ===============\n",
      "iter 504, current loss=26101.806612244312\n",
      "================ STEP 394 ===============\n",
      "iter 505, current loss=26058.30329056395\n",
      "================ STEP 395 ===============\n",
      "iter 506, current loss=25993.882940875537\n",
      "================ STEP 396 ===============\n",
      "iter 507, current loss=25840.32965369474\n",
      "================ STEP 397 ===============\n",
      "iter 508, current loss=25797.26218608203\n",
      "================ STEP 398 ===============\n",
      "iter 509, current loss=25779.43130425714\n",
      "================ STEP 399 ===============\n",
      "iter 510, current loss=25773.40485691934\n",
      "================ STEP 400 ===============\n",
      "iter 511, current loss=25727.949524200878\n",
      "================ STEP 401 ===============\n",
      "iter 512, current loss=25690.26954393084\n",
      "================ STEP 402 ===============\n",
      "iter 513, current loss=25649.696092375365\n",
      "================ STEP 403 ===============\n",
      "iter 514, current loss=25993.878958418773\n",
      "iter 515, current loss=25608.998007647737\n",
      "================ STEP 404 ===============\n",
      "iter 516, current loss=25491.706167375247\n",
      "================ STEP 405 ===============\n",
      "iter 517, current loss=25361.024632767527\n",
      "================ STEP 406 ===============\n",
      "iter 518, current loss=25252.400665159927\n",
      "================ STEP 407 ===============\n",
      "iter 519, current loss=25231.784450895546\n",
      "================ STEP 408 ===============\n",
      "iter 520, current loss=25221.020548137683\n",
      "================ STEP 409 ===============\n",
      "iter 521, current loss=25207.67248085937\n",
      "================ STEP 410 ===============\n",
      "iter 522, current loss=25187.721377118833\n",
      "================ STEP 411 ===============\n",
      "iter 523, current loss=25165.665733488917\n",
      "================ STEP 412 ===============\n",
      "iter 524, current loss=28020.380129270703\n",
      "iter 525, current loss=25146.973050073335\n",
      "================ STEP 413 ===============\n",
      "iter 526, current loss=25103.829796137612\n",
      "================ STEP 414 ===============\n",
      "iter 527, current loss=25083.83815210902\n",
      "================ STEP 415 ===============\n",
      "iter 528, current loss=25051.69403839058\n",
      "================ STEP 416 ===============\n",
      "iter 529, current loss=25024.292372142772\n",
      "================ STEP 417 ===============\n",
      "iter 530, current loss=24935.82052725012\n",
      "================ STEP 418 ===============\n",
      "iter 531, current loss=25107.974990172173\n",
      "iter 532, current loss=24894.20238545503\n",
      "================ STEP 419 ===============\n",
      "iter 533, current loss=24755.868350812925\n",
      "================ STEP 420 ===============\n",
      "iter 534, current loss=24428.985351958483\n",
      "================ STEP 421 ===============\n",
      "iter 535, current loss=24267.037968403918\n",
      "================ STEP 422 ===============\n",
      "iter 536, current loss=24028.799408781175\n",
      "================ STEP 423 ===============\n",
      "iter 537, current loss=23964.729069049863\n",
      "================ STEP 424 ===============\n",
      "iter 538, current loss=23833.24064880312\n",
      "================ STEP 425 ===============\n",
      "iter 539, current loss=23722.42242351159\n",
      "================ STEP 426 ===============\n",
      "iter 540, current loss=23441.400548694677\n",
      "================ STEP 427 ===============\n",
      "iter 541, current loss=23009.460992135646\n",
      "================ STEP 428 ===============\n",
      "iter 542, current loss=22257.943161162875\n",
      "================ STEP 429 ===============\n",
      "iter 543, current loss=22164.058476466686\n",
      "iter 544, current loss=21738.596987357312\n",
      "================ STEP 430 ===============\n",
      "iter 545, current loss=20556.843488839164\n",
      "================ STEP 431 ===============\n",
      "iter 546, current loss=19798.71499646283\n",
      "================ STEP 432 ===============\n",
      "iter 547, current loss=18897.45785495024\n",
      "================ STEP 433 ===============\n",
      "iter 548, current loss=18329.744304452535\n",
      "================ STEP 434 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 549, current loss=17940.201576832576\n",
      "================ STEP 435 ===============\n",
      "iter 550, current loss=17641.69556392952\n",
      "================ STEP 436 ===============\n",
      "iter 551, current loss=17463.1439552504\n",
      "================ STEP 437 ===============\n",
      "iter 552, current loss=17268.400839356764\n",
      "================ STEP 438 ===============\n",
      "iter 553, current loss=18336.776556930028\n",
      "iter 554, current loss=17240.528733891177\n",
      "================ STEP 439 ===============\n",
      "iter 555, current loss=17465.655602261264\n",
      "iter 556, current loss=17128.41611938893\n",
      "================ STEP 440 ===============\n",
      "iter 557, current loss=16935.346204329708\n",
      "================ STEP 441 ===============\n",
      "iter 558, current loss=16719.860159520787\n",
      "================ STEP 442 ===============\n",
      "iter 559, current loss=16400.322285188817\n",
      "================ STEP 443 ===============\n",
      "iter 560, current loss=15669.187632441775\n",
      "================ STEP 444 ===============\n",
      "iter 561, current loss=35078.7774239179\n",
      "iter 562, current loss=15311.323653581505\n",
      "================ STEP 445 ===============\n",
      "iter 563, current loss=14355.817095421287\n",
      "================ STEP 446 ===============\n",
      "iter 564, current loss=13223.421432356223\n",
      "================ STEP 447 ===============\n",
      "iter 565, current loss=151730.37323751295\n",
      "iter 566, current loss=13038.339879321786\n",
      "================ STEP 448 ===============\n",
      "iter 567, current loss=13486.27868050104\n",
      "iter 568, current loss=12773.601447563786\n",
      "================ STEP 449 ===============\n",
      "iter 569, current loss=13054.902033454977\n",
      "iter 570, current loss=12619.559600814006\n",
      "================ STEP 450 ===============\n",
      "iter 571, current loss=12452.9204101609\n",
      "================ STEP 451 ===============\n",
      "iter 572, current loss=12190.963648799903\n",
      "================ STEP 452 ===============\n",
      "iter 573, current loss=11924.90483624935\n",
      "================ STEP 453 ===============\n",
      "iter 574, current loss=11920.119391228114\n",
      "iter 575, current loss=11889.41757518031\n",
      "================ STEP 454 ===============\n",
      "iter 576, current loss=11826.273868621514\n",
      "================ STEP 455 ===============\n",
      "iter 577, current loss=11551.258174209599\n",
      "================ STEP 456 ===============\n",
      "iter 578, current loss=11166.228647295635\n",
      "================ STEP 457 ===============\n",
      "iter 579, current loss=11363.580098414102\n",
      "iter 580, current loss=10904.626460626168\n",
      "================ STEP 458 ===============\n",
      "iter 581, current loss=10644.010424342243\n",
      "================ STEP 459 ===============\n",
      "iter 582, current loss=10629.103074002269\n",
      "================ STEP 460 ===============\n",
      "iter 583, current loss=10506.913793303705\n",
      "================ STEP 461 ===============\n",
      "iter 584, current loss=10334.475046243002\n",
      "================ STEP 462 ===============\n",
      "iter 585, current loss=10037.917837373132\n",
      "================ STEP 463 ===============\n",
      "iter 586, current loss=9829.655964226888\n",
      "================ STEP 464 ===============\n",
      "iter 587, current loss=15084.852556713508\n",
      "iter 588, current loss=9769.003094879516\n",
      "================ STEP 465 ===============\n",
      "iter 589, current loss=9484.115650905125\n",
      "================ STEP 466 ===============\n",
      "iter 590, current loss=9291.212458291717\n",
      "================ STEP 467 ===============\n",
      "iter 591, current loss=9205.824276697396\n",
      "================ STEP 468 ===============\n",
      "iter 592, current loss=9147.202876890287\n",
      "================ STEP 469 ===============\n",
      "iter 593, current loss=8971.041823788291\n",
      "================ STEP 470 ===============\n",
      "iter 594, current loss=8732.130319354785\n",
      "================ STEP 471 ===============\n",
      "iter 595, current loss=28567.807397242097\n",
      "iter 596, current loss=8564.698045668132\n",
      "================ STEP 472 ===============\n",
      "iter 597, current loss=8146.381550362807\n",
      "iter 598, current loss=8089.521088200807\n",
      "================ STEP 473 ===============\n",
      "iter 599, current loss=7553.90064854146\n",
      "================ STEP 474 ===============\n",
      "iter 600, current loss=9135.939073012727\n",
      "iter 601, current loss=7331.028645717434\n",
      "================ STEP 475 ===============\n",
      "iter 602, current loss=7114.283189872378\n",
      "================ STEP 476 ===============\n",
      "iter 603, current loss=6796.484180707832\n",
      "================ STEP 477 ===============\n",
      "iter 604, current loss=6613.372829258955\n",
      "================ STEP 478 ===============\n",
      "iter 605, current loss=6432.321363151995\n",
      "================ STEP 479 ===============\n",
      "iter 606, current loss=6248.66287752055\n",
      "iter 607, current loss=6249.30819708416\n",
      "================ STEP 480 ===============\n",
      "iter 608, current loss=6440.5554225414435\n",
      "iter 609, current loss=6056.074589645211\n",
      "================ STEP 481 ===============\n",
      "iter 610, current loss=5927.896961718632\n",
      "================ STEP 482 ===============\n",
      "iter 611, current loss=5796.023797202461\n",
      "================ STEP 483 ===============\n",
      "iter 612, current loss=5685.139846346302\n",
      "================ STEP 484 ===============\n",
      "iter 613, current loss=5594.708946292958\n",
      "================ STEP 485 ===============\n",
      "iter 614, current loss=5347.138264881514\n",
      "================ STEP 486 ===============\n",
      "iter 615, current loss=5097.962110651801\n",
      "================ STEP 487 ===============\n",
      "iter 616, current loss=4622.727167402497\n",
      "================ STEP 488 ===============\n",
      "iter 617, current loss=11605.3826691631\n",
      "iter 618, current loss=4247.359083266065\n",
      "================ STEP 489 ===============\n",
      "iter 619, current loss=3766.4609222615245\n",
      "iter 620, current loss=3566.9401595026775\n",
      "================ STEP 490 ===============\n",
      "iter 621, current loss=3385.9886005286\n",
      "iter 622, current loss=2891.2252143316628\n",
      "================ STEP 491 ===============\n",
      "iter 623, current loss=2558.3256649788295\n",
      "================ STEP 492 ===============\n",
      "iter 624, current loss=2994.5379381854877\n",
      "iter 625, current loss=2530.90867400587\n",
      "================ STEP 493 ===============\n",
      "iter 626, current loss=2443.5532954868395\n",
      "================ STEP 494 ===============\n",
      "iter 627, current loss=2330.2789655137008\n",
      "================ STEP 495 ===============\n",
      "iter 628, current loss=2093.442437981109\n",
      "================ STEP 496 ===============\n",
      "iter 629, current loss=2003.6794965890076\n",
      "================ STEP 497 ===============\n",
      "iter 630, current loss=1943.9126710115747\n",
      "================ STEP 498 ===============\n",
      "iter 631, current loss=1905.786992277812\n",
      "================ STEP 499 ===============\n",
      "iter 632, current loss=1825.9200644727184\n",
      "================ STEP 500 ===============\n",
      "iter 633, current loss=1675.8475804009875\n",
      "================ STEP 501 ===============\n",
      "iter 634, current loss=1502.806901940265\n",
      "================ STEP 502 ===============\n",
      "iter 635, current loss=1432.7419189592442\n",
      "================ STEP 503 ===============\n",
      "iter 636, current loss=6298.2499270925855\n",
      "iter 637, current loss=1390.4413731259272\n",
      "================ STEP 504 ===============\n",
      "iter 638, current loss=1287.9827122981603\n",
      "================ STEP 505 ===============\n",
      "iter 639, current loss=1284.7202159261647\n",
      "iter 640, current loss=1267.4110424863438\n",
      "================ STEP 506 ===============\n",
      "iter 641, current loss=1246.280842591292\n",
      "================ STEP 507 ===============\n",
      "iter 642, current loss=1253.5844038862474\n",
      "iter 643, current loss=1200.5484258978133\n",
      "================ STEP 508 ===============\n",
      "iter 644, current loss=1169.0362319596434\n",
      "================ STEP 509 ===============\n",
      "iter 645, current loss=1175.3666722794237\n",
      "iter 646, current loss=1161.2844398239818\n",
      "================ STEP 510 ===============\n",
      "iter 647, current loss=1155.350722909257\n",
      "================ STEP 511 ===============\n",
      "iter 648, current loss=1148.4215598557828\n",
      "================ STEP 512 ===============\n",
      "iter 649, current loss=1148.1757316001676\n",
      "================ STEP 513 ===============\n",
      "iter 650, current loss=1147.4342174353326\n",
      "================ STEP 514 ===============\n",
      "iter 651, current loss=1145.845570031608\n",
      "================ STEP 515 ===============\n",
      "iter 652, current loss=1142.4000348042796\n",
      "================ STEP 516 ===============\n",
      "iter 653, current loss=1137.5055899660765\n",
      "================ STEP 517 ===============\n",
      "iter 654, current loss=1125.9889042223226\n",
      "================ STEP 518 ===============\n",
      "iter 655, current loss=1097.9330642651817\n",
      "================ STEP 519 ===============\n",
      "iter 656, current loss=1064.3483693888093\n",
      "================ STEP 520 ===============\n",
      "iter 657, current loss=1032.1783315000457\n",
      "================ STEP 521 ===============\n",
      "iter 658, current loss=1002.4377856361953\n",
      "================ STEP 522 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 659, current loss=963.8527285866201\n",
      "================ STEP 523 ===============\n",
      "iter 660, current loss=925.2242756100999\n",
      "================ STEP 524 ===============\n",
      "iter 661, current loss=881.4810332559061\n",
      "================ STEP 525 ===============\n",
      "iter 662, current loss=872.5509809914956\n",
      "================ STEP 526 ===============\n",
      "iter 663, current loss=853.7975006152549\n",
      "================ STEP 527 ===============\n",
      "iter 664, current loss=835.1842186617567\n",
      "================ STEP 528 ===============\n",
      "iter 665, current loss=828.810332410102\n",
      "================ STEP 529 ===============\n",
      "iter 666, current loss=820.1636414910686\n",
      "================ STEP 530 ===============\n",
      "iter 667, current loss=817.2912669021409\n",
      "================ STEP 531 ===============\n",
      "iter 668, current loss=810.755703070251\n",
      "================ STEP 532 ===============\n",
      "iter 669, current loss=809.9238037294804\n",
      "================ STEP 533 ===============\n",
      "iter 670, current loss=806.4019379415874\n",
      "================ STEP 534 ===============\n",
      "iter 671, current loss=804.6575129444748\n",
      "================ STEP 535 ===============\n",
      "iter 672, current loss=803.1768068850739\n",
      "================ STEP 536 ===============\n",
      "iter 673, current loss=802.4614201953858\n",
      "================ STEP 537 ===============\n",
      "iter 674, current loss=801.9622163889625\n",
      "================ STEP 538 ===============\n",
      "iter 675, current loss=801.7915662726066\n",
      "================ STEP 539 ===============\n",
      "iter 676, current loss=801.4913642962483\n",
      "================ STEP 540 ===============\n",
      "iter 677, current loss=800.5703421063104\n",
      "================ STEP 541 ===============\n",
      "iter 678, current loss=811.5741773363725\n",
      "iter 679, current loss=800.4243601118255\n",
      "================ STEP 542 ===============\n",
      "iter 680, current loss=799.9524846340973\n",
      "================ STEP 543 ===============\n",
      "iter 681, current loss=804.9367757593643\n",
      "iter 682, current loss=798.959332914512\n",
      "================ STEP 544 ===============\n",
      "iter 683, current loss=796.518186354318\n",
      "================ STEP 545 ===============\n",
      "iter 684, current loss=792.3266357061171\n",
      "================ STEP 546 ===============\n",
      "iter 685, current loss=783.0349176127811\n",
      "================ STEP 547 ===============\n",
      "iter 686, current loss=777.2751351897703\n",
      "================ STEP 548 ===============\n",
      "iter 687, current loss=773.6631113320223\n",
      "================ STEP 549 ===============\n",
      "iter 688, current loss=771.6329569952486\n",
      "================ STEP 550 ===============\n",
      "iter 689, current loss=768.4257778775736\n",
      "================ STEP 551 ===============\n",
      "iter 690, current loss=768.087310803568\n",
      "================ STEP 552 ===============\n",
      "iter 691, current loss=767.881690076748\n",
      "================ STEP 553 ===============\n",
      "iter 692, current loss=767.5430859653845\n",
      "================ STEP 554 ===============\n",
      "iter 693, current loss=767.1583583922859\n",
      "================ STEP 555 ===============\n",
      "iter 694, current loss=766.6850686100108\n",
      "================ STEP 556 ===============\n",
      "iter 695, current loss=765.9971165625893\n",
      "================ STEP 557 ===============\n",
      "iter 696, current loss=765.1939018418119\n",
      "================ STEP 558 ===============\n",
      "iter 697, current loss=763.5731693948039\n",
      "================ STEP 559 ===============\n",
      "iter 698, current loss=761.8121890656703\n",
      "================ STEP 560 ===============\n",
      "iter 699, current loss=760.0225475917188\n",
      "================ STEP 561 ===============\n",
      "iter 700, current loss=783.2567399253271\n",
      "iter 701, current loss=759.950776764752\n",
      "================ STEP 562 ===============\n",
      "iter 702, current loss=759.6365731199571\n",
      "================ STEP 563 ===============\n",
      "iter 703, current loss=759.2914098961392\n",
      "================ STEP 564 ===============\n",
      "iter 704, current loss=759.5873449248547\n",
      "iter 705, current loss=759.2039908939466\n",
      "================ STEP 565 ===============\n",
      "iter 706, current loss=758.9847355570369\n",
      "================ STEP 566 ===============\n",
      "iter 707, current loss=758.8258097807939\n",
      "================ STEP 567 ===============\n",
      "iter 708, current loss=758.6812719467271\n",
      "================ STEP 568 ===============\n",
      "iter 709, current loss=758.2059261256954\n",
      "================ STEP 569 ===============\n",
      "iter 710, current loss=757.6396303087238\n",
      "================ STEP 570 ===============\n",
      "iter 711, current loss=756.444613804324\n",
      "================ STEP 571 ===============\n",
      "iter 712, current loss=754.8221173204761\n",
      "================ STEP 572 ===============\n",
      "iter 713, current loss=756.0470410191645\n",
      "iter 714, current loss=753.7790667273626\n",
      "================ STEP 573 ===============\n",
      "iter 715, current loss=751.9867294290731\n",
      "================ STEP 574 ===============\n",
      "iter 716, current loss=751.6383388880831\n",
      "================ STEP 575 ===============\n",
      "iter 717, current loss=751.3262696308146\n",
      "================ STEP 576 ===============\n",
      "iter 718, current loss=750.9976595268738\n",
      "================ STEP 577 ===============\n",
      "iter 719, current loss=750.1487903853508\n",
      "================ STEP 578 ===============\n",
      "iter 720, current loss=748.7930871361102\n",
      "================ STEP 579 ===============\n",
      "iter 721, current loss=748.1028575133513\n",
      "================ STEP 580 ===============\n",
      "iter 722, current loss=747.707221821399\n",
      "================ STEP 581 ===============\n",
      "iter 723, current loss=747.4865154528686\n",
      "================ STEP 582 ===============\n",
      "iter 724, current loss=746.60964689045\n",
      "================ STEP 583 ===============\n",
      "iter 725, current loss=745.6852069884297\n",
      "================ STEP 584 ===============\n",
      "iter 726, current loss=747.2540385824911\n",
      "iter 727, current loss=745.0756711949064\n",
      "================ STEP 585 ===============\n",
      "iter 728, current loss=743.8795631246973\n",
      "================ STEP 586 ===============\n",
      "iter 729, current loss=743.4531864475946\n",
      "================ STEP 587 ===============\n",
      "iter 730, current loss=743.3318575689237\n",
      "================ STEP 588 ===============\n",
      "iter 731, current loss=743.2347476322996\n",
      "================ STEP 589 ===============\n",
      "iter 732, current loss=742.931667616574\n",
      "================ STEP 590 ===============\n",
      "iter 733, current loss=742.7593810101921\n",
      "================ STEP 591 ===============\n",
      "iter 734, current loss=742.3690498873003\n",
      "================ STEP 592 ===============\n",
      "iter 735, current loss=743.7268954134481\n",
      "iter 736, current loss=742.0453101453228\n",
      "================ STEP 593 ===============\n",
      "iter 737, current loss=741.3531928127351\n",
      "================ STEP 594 ===============\n",
      "iter 738, current loss=739.8356999391724\n",
      "================ STEP 595 ===============\n",
      "iter 739, current loss=740.621540017615\n",
      "iter 740, current loss=739.5383401002227\n",
      "================ STEP 596 ===============\n",
      "iter 741, current loss=739.2097073716247\n",
      "================ STEP 597 ===============\n",
      "iter 742, current loss=738.937718793508\n",
      "================ STEP 598 ===============\n",
      "iter 743, current loss=738.4035923599147\n",
      "================ STEP 599 ===============\n",
      "iter 744, current loss=737.3079099985862\n",
      "================ STEP 600 ===============\n",
      "iter 745, current loss=734.9316677439822\n",
      "================ STEP 601 ===============\n",
      "iter 746, current loss=728.2652167151384\n",
      "================ STEP 602 ===============\n",
      "iter 747, current loss=720.4528674569572\n",
      "================ STEP 603 ===============\n",
      "iter 748, current loss=713.797733586197\n",
      "================ STEP 604 ===============\n",
      "iter 749, current loss=718.5659851548342\n",
      "iter 750, current loss=707.5564482091852\n",
      "================ STEP 605 ===============\n",
      "iter 751, current loss=707.0892353391073\n",
      "iter 752, current loss=696.0427006003085\n",
      "================ STEP 606 ===============\n",
      "iter 753, current loss=697.0251293055585\n",
      "iter 754, current loss=691.166489674503\n",
      "================ STEP 607 ===============\n",
      "iter 755, current loss=688.4403356921041\n",
      "================ STEP 608 ===============\n",
      "iter 756, current loss=685.213536345971\n",
      "================ STEP 609 ===============\n",
      "iter 757, current loss=1477.7799632713347\n",
      "iter 758, current loss=684.2519603020044\n",
      "================ STEP 610 ===============\n",
      "iter 759, current loss=683.3891895710718\n",
      "================ STEP 611 ===============\n",
      "iter 760, current loss=680.4053779406102\n",
      "================ STEP 612 ===============\n",
      "iter 761, current loss=679.3075439151396\n",
      "================ STEP 613 ===============\n",
      "iter 762, current loss=677.1664709139887\n",
      "================ STEP 614 ===============\n",
      "iter 763, current loss=675.5113746249547\n",
      "================ STEP 615 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 764, current loss=677.065277142462\n",
      "iter 765, current loss=671.1009401426031\n",
      "================ STEP 616 ===============\n",
      "iter 766, current loss=667.8837380591254\n",
      "================ STEP 617 ===============\n",
      "iter 767, current loss=665.1287328672311\n",
      "================ STEP 618 ===============\n",
      "iter 768, current loss=662.3817038689326\n",
      "================ STEP 619 ===============\n",
      "iter 769, current loss=662.2006660061045\n",
      "================ STEP 620 ===============\n",
      "iter 770, current loss=661.1336721133874\n",
      "================ STEP 621 ===============\n",
      "iter 771, current loss=660.9805337970255\n",
      "================ STEP 622 ===============\n",
      "iter 772, current loss=660.8300771936347\n",
      "================ STEP 623 ===============\n",
      "iter 773, current loss=660.6611907411555\n",
      "================ STEP 624 ===============\n",
      "iter 774, current loss=660.5713929464963\n",
      "================ STEP 625 ===============\n",
      "iter 775, current loss=660.6145536719661\n",
      "iter 776, current loss=660.4708852291419\n",
      "================ STEP 626 ===============\n",
      "iter 777, current loss=660.3812805389422\n",
      "================ STEP 627 ===============\n",
      "iter 778, current loss=660.2894500354885\n",
      "================ STEP 628 ===============\n",
      "iter 779, current loss=660.0897063172389\n",
      "================ STEP 629 ===============\n",
      "iter 780, current loss=660.0833256934662\n",
      "================ STEP 630 ===============\n",
      "iter 781, current loss=660.0459875182314\n",
      "================ STEP 631 ===============\n",
      "iter 782, current loss=660.0337681162187\n",
      "================ STEP 632 ===============\n",
      "iter 783, current loss=660.249354429909\n",
      "iter 784, current loss=660.0195106701613\n",
      "================ STEP 633 ===============\n",
      "iter 785, current loss=659.9909889767133\n",
      "================ STEP 634 ===============\n",
      "iter 786, current loss=659.9215940841907\n",
      "================ STEP 635 ===============\n",
      "iter 787, current loss=659.866851769689\n",
      "================ STEP 636 ===============\n",
      "iter 788, current loss=659.7475224306424\n",
      "================ STEP 637 ===============\n",
      "iter 789, current loss=659.5799011354234\n",
      "================ STEP 638 ===============\n",
      "iter 790, current loss=659.3579409711375\n",
      "================ STEP 639 ===============\n",
      "iter 791, current loss=659.2820463717247\n",
      "================ STEP 640 ===============\n",
      "iter 792, current loss=659.1715551671948\n",
      "================ STEP 641 ===============\n",
      "iter 793, current loss=659.0307480420918\n",
      "================ STEP 642 ===============\n",
      "iter 794, current loss=658.5835463859645\n",
      "================ STEP 643 ===============\n",
      "iter 795, current loss=658.1369341172235\n",
      "================ STEP 644 ===============\n",
      "iter 796, current loss=657.742463977334\n",
      "================ STEP 645 ===============\n",
      "iter 797, current loss=657.7914569033996\n",
      "iter 798, current loss=657.4926114597812\n",
      "================ STEP 646 ===============\n",
      "iter 799, current loss=657.19625891222\n",
      "================ STEP 647 ===============\n",
      "iter 800, current loss=656.9273426121455\n",
      "================ STEP 648 ===============\n",
      "iter 801, current loss=656.8335465902601\n",
      "================ STEP 649 ===============\n",
      "iter 802, current loss=656.7886679088022\n",
      "================ STEP 650 ===============\n",
      "iter 803, current loss=658.7372549229264\n",
      "iter 804, current loss=656.7696220236562\n",
      "================ STEP 651 ===============\n",
      "iter 805, current loss=656.7473234258821\n",
      "================ STEP 652 ===============\n",
      "iter 806, current loss=656.7090110400516\n",
      "================ STEP 653 ===============\n",
      "iter 807, current loss=656.6364356514415\n",
      "================ STEP 654 ===============\n",
      "iter 808, current loss=656.5938959854509\n",
      "================ STEP 655 ===============\n",
      "iter 809, current loss=656.4156742185392\n",
      "================ STEP 656 ===============\n",
      "iter 810, current loss=656.4159225116098\n",
      "iter 811, current loss=656.3637412652597\n",
      "================ STEP 657 ===============\n",
      "iter 812, current loss=656.2834411403353\n",
      "================ STEP 658 ===============\n",
      "iter 813, current loss=656.1899408825892\n",
      "================ STEP 659 ===============\n",
      "iter 814, current loss=656.0064278035891\n",
      "================ STEP 660 ===============\n",
      "iter 815, current loss=655.8924323394746\n",
      "================ STEP 661 ===============\n",
      "iter 816, current loss=655.5369060094146\n",
      "================ STEP 662 ===============\n",
      "iter 817, current loss=655.3179190568458\n",
      "================ STEP 663 ===============\n",
      "iter 818, current loss=654.7671844063829\n",
      "================ STEP 664 ===============\n",
      "iter 819, current loss=654.2841550447104\n",
      "================ STEP 665 ===============\n",
      "iter 820, current loss=653.904345364725\n",
      "================ STEP 666 ===============\n",
      "iter 821, current loss=653.4108403935375\n",
      "================ STEP 667 ===============\n",
      "iter 822, current loss=653.3483825198132\n",
      "iter 823, current loss=653.132971830482\n",
      "================ STEP 668 ===============\n",
      "iter 824, current loss=656.4957867188498\n",
      "iter 825, current loss=652.6079009386865\n",
      "================ STEP 669 ===============\n",
      "iter 826, current loss=652.2977581306178\n",
      "================ STEP 670 ===============\n",
      "iter 827, current loss=651.5502919172351\n",
      "================ STEP 671 ===============\n",
      "iter 828, current loss=651.2908908040167\n",
      "================ STEP 672 ===============\n",
      "iter 829, current loss=650.878707811728\n",
      "================ STEP 673 ===============\n",
      "iter 830, current loss=650.1581517029801\n",
      "================ STEP 674 ===============\n",
      "iter 831, current loss=648.339240968894\n",
      "================ STEP 675 ===============\n",
      "iter 832, current loss=655.0469583709494\n",
      "iter 833, current loss=647.7134611244278\n",
      "================ STEP 676 ===============\n",
      "iter 834, current loss=646.7707374230502\n",
      "================ STEP 677 ===============\n",
      "iter 835, current loss=645.7693317482335\n",
      "================ STEP 678 ===============\n",
      "iter 836, current loss=645.154538706915\n",
      "================ STEP 679 ===============\n",
      "iter 837, current loss=644.5311410203335\n",
      "================ STEP 680 ===============\n",
      "iter 838, current loss=643.0814910508129\n",
      "================ STEP 681 ===============\n",
      "iter 839, current loss=642.5333749796702\n",
      "================ STEP 682 ===============\n",
      "iter 840, current loss=641.9665612187622\n",
      "================ STEP 683 ===============\n",
      "iter 841, current loss=641.6710284189695\n",
      "================ STEP 684 ===============\n",
      "iter 842, current loss=640.8598171614819\n",
      "================ STEP 685 ===============\n",
      "iter 843, current loss=638.1695656647871\n",
      "================ STEP 686 ===============\n",
      "iter 844, current loss=681.5734931456351\n",
      "iter 845, current loss=636.6608382713925\n",
      "================ STEP 687 ===============\n",
      "iter 846, current loss=633.2571904540895\n",
      "================ STEP 688 ===============\n",
      "iter 847, current loss=630.5764848045037\n",
      "================ STEP 689 ===============\n",
      "iter 848, current loss=628.8929516957605\n",
      "================ STEP 690 ===============\n",
      "iter 849, current loss=626.7506581442569\n",
      "================ STEP 691 ===============\n",
      "iter 850, current loss=622.8412471280795\n",
      "================ STEP 692 ===============\n",
      "iter 851, current loss=617.5169634767669\n",
      "================ STEP 693 ===============\n",
      "iter 852, current loss=609.2349964650739\n",
      "================ STEP 694 ===============\n",
      "iter 853, current loss=600.5245143438137\n",
      "================ STEP 695 ===============\n",
      "iter 854, current loss=585.7491863199828\n",
      "================ STEP 696 ===============\n",
      "iter 855, current loss=593.1654949245203\n",
      "iter 856, current loss=579.6438688151037\n",
      "================ STEP 697 ===============\n",
      "iter 857, current loss=572.1683310678325\n",
      "================ STEP 698 ===============\n",
      "iter 858, current loss=562.1737527978902\n",
      "================ STEP 699 ===============\n",
      "iter 859, current loss=557.2760752385371\n",
      "================ STEP 700 ===============\n",
      "iter 860, current loss=546.052371353725\n",
      "================ STEP 701 ===============\n",
      "iter 861, current loss=957.2732094657672\n",
      "iter 862, current loss=538.7842250765594\n",
      "================ STEP 702 ===============\n",
      "iter 863, current loss=522.7565898458026\n",
      "================ STEP 703 ===============\n",
      "iter 864, current loss=518.354595510905\n",
      "================ STEP 704 ===============\n",
      "iter 865, current loss=516.3700827066716\n",
      "================ STEP 705 ===============\n",
      "iter 866, current loss=515.2103109104795\n",
      "================ STEP 706 ===============\n",
      "iter 867, current loss=514.272853246472\n",
      "================ STEP 707 ===============\n",
      "iter 868, current loss=515.64068644474\n",
      "iter 869, current loss=514.0997716887548\n",
      "================ STEP 708 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 870, current loss=513.8292377844634\n",
      "================ STEP 709 ===============\n",
      "iter 871, current loss=513.0134552707118\n",
      "================ STEP 710 ===============\n",
      "iter 872, current loss=512.187908091729\n",
      "================ STEP 711 ===============\n",
      "iter 873, current loss=512.2156938763678\n",
      "iter 874, current loss=511.6386554449605\n",
      "================ STEP 712 ===============\n",
      "iter 875, current loss=511.96230404883966\n",
      "iter 876, current loss=511.33467000999553\n",
      "================ STEP 713 ===============\n",
      "iter 877, current loss=527.8184280576995\n",
      "iter 878, current loss=510.8218197103181\n",
      "================ STEP 714 ===============\n",
      "iter 879, current loss=510.3027942256889\n",
      "================ STEP 715 ===============\n",
      "iter 880, current loss=508.91122728109076\n",
      "================ STEP 716 ===============\n",
      "iter 881, current loss=507.6370053300295\n",
      "================ STEP 717 ===============\n",
      "iter 882, current loss=504.42065867310214\n",
      "================ STEP 718 ===============\n",
      "iter 883, current loss=498.5409526754056\n",
      "================ STEP 719 ===============\n",
      "iter 884, current loss=493.85230697715565\n",
      "================ STEP 720 ===============\n",
      "iter 885, current loss=488.89486832506213\n",
      "================ STEP 721 ===============\n",
      "iter 886, current loss=487.43427094864285\n",
      "================ STEP 722 ===============\n",
      "iter 887, current loss=486.9275945493229\n",
      "================ STEP 723 ===============\n",
      "iter 888, current loss=485.87461227213595\n",
      "================ STEP 724 ===============\n",
      "iter 889, current loss=485.60828565881195\n",
      "================ STEP 725 ===============\n",
      "iter 890, current loss=484.26471723357685\n",
      "================ STEP 726 ===============\n",
      "iter 891, current loss=483.78089735585803\n",
      "================ STEP 727 ===============\n",
      "iter 892, current loss=482.8858880232531\n",
      "================ STEP 728 ===============\n",
      "iter 893, current loss=482.07566638153213\n",
      "================ STEP 729 ===============\n",
      "iter 894, current loss=480.51849083996433\n",
      "================ STEP 730 ===============\n",
      "iter 895, current loss=479.4214584875357\n",
      "================ STEP 731 ===============\n",
      "iter 896, current loss=478.957780140209\n",
      "================ STEP 732 ===============\n",
      "iter 897, current loss=477.8083574741736\n",
      "================ STEP 733 ===============\n",
      "iter 898, current loss=477.4250855561728\n",
      "================ STEP 734 ===============\n",
      "iter 899, current loss=476.5288039802001\n",
      "================ STEP 735 ===============\n",
      "iter 900, current loss=492.0685290215856\n",
      "iter 901, current loss=476.1282091269899\n",
      "================ STEP 736 ===============\n",
      "iter 902, current loss=474.81850764698066\n",
      "================ STEP 737 ===============\n",
      "iter 903, current loss=473.9690187573317\n",
      "================ STEP 738 ===============\n",
      "iter 904, current loss=482.8057723805473\n",
      "iter 905, current loss=473.66791361709784\n",
      "================ STEP 739 ===============\n",
      "iter 906, current loss=473.2269267512197\n",
      "================ STEP 740 ===============\n",
      "iter 907, current loss=473.04231343955627\n",
      "================ STEP 741 ===============\n",
      "iter 908, current loss=472.9385854941386\n",
      "================ STEP 742 ===============\n",
      "iter 909, current loss=472.72909581758415\n",
      "================ STEP 743 ===============\n",
      "iter 910, current loss=472.23605817641595\n",
      "================ STEP 744 ===============\n",
      "iter 911, current loss=472.00318473902246\n",
      "================ STEP 745 ===============\n",
      "iter 912, current loss=471.7170533181308\n",
      "================ STEP 746 ===============\n",
      "iter 913, current loss=471.6473578156708\n",
      "================ STEP 747 ===============\n",
      "iter 914, current loss=471.79029091054355\n",
      "iter 915, current loss=471.597594367309\n",
      "================ STEP 748 ===============\n",
      "iter 916, current loss=471.5271717215378\n",
      "================ STEP 749 ===============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2001×7 Array{Float64,2}:\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.0    0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.001  0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "  500.001  0.166667     0.166667  0.166667   0.166667  0.166667   0.166667\n",
       "    ⋮                                                  ⋮          \n",
       " 3072.45   0.000112686  0.322874  0.0971148  0.360824  0.052408   0.166667\n",
       " 3072.51   0.0001124    0.322902  0.0971022  0.360911  0.0523054  0.166667\n",
       " 3072.57   0.000112116  0.32293   0.0970897  0.360998  0.0522029  0.166667\n",
       " 3072.62   0.000111832  0.322958  0.0970771  0.361085  0.0521008  0.166667\n",
       " 3072.68   0.000111548  0.322986  0.0970647  0.361172  0.0519988  0.166667\n",
       " 3072.74   0.000111266  0.323014  0.0970522  0.361258  0.0518971  0.166667\n",
       " 3072.8    0.000110985  0.323042  0.0970398  0.361345  0.0517956  0.166667\n",
       " 3072.85   0.000110704  0.32307   0.0970274  0.361431  0.0516944  0.166667\n",
       " 3072.91   0.000110425  0.323098  0.097015   0.361517  0.0515934  0.166667\n",
       " 3072.97   0.000110146  0.323126  0.0970027  0.361602  0.0514926  0.166667\n",
       " 3073.03   0.000109868  0.323153  0.0969904  0.361688  0.051392   0.166667\n",
       " 3073.09   0.000109591  0.323181  0.0969781  0.361773  0.0512917  0.166667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt = size(timestep)[1]\n",
    "inds = range(1,2000, step=50)\n",
    "TY = [T; Y]\n",
    "function condition(k, U, t)\n",
    "    k <= nt - 1\n",
    "end\n",
    "\n",
    "function body(k, U, t)\n",
    "    dt = t[k + 1] - t[k]\n",
    "    uk = read(U,k)\n",
    "    k1 = f(uk, Qdot[k], t[k])\n",
    "    k2 = f(uk + 0.5 * dt * k1, Qdot[k], t[k] + 0.5 * dt)\n",
    "    k3 = f(uk + 0.5 * dt * k2, Qdot[k], t[k] + 0.5 * dt)\n",
    "    k4 = f(uk + dt * k3, Qdot[k], t[k] + dt) \n",
    "    u_new = uk + 1/6 * dt * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    U = write(U, k+1, u_new)\n",
    "    k+1, U, t\n",
    "end\n",
    "k = constant(1, dtype=Int32)\n",
    "t = constant(timestep)\n",
    "θ = Variable(fc_init([1,20,20,1]))\n",
    "C = Variable(3.0)\n",
    "#theta = Variable([8.0, 0.8])\n",
    "Qdtb = abs(fc(t * 1e5, [20,20,1], θ))\n",
    "Qdot = 1.8 * (1.0 / (1.0 + exp(-C))) * 1e6 * Qdtb / sum(Qdtb[1:end-1] * (t[2:end] - t[1:end-1]))\n",
    "U = TensorArray(nt)\n",
    "U = write(U, 1, TY)\n",
    "_, U_out=while_loop(condition, body, [k, U, t])\n",
    "U_array = set_shape(stack(U_out), (nt, N+1))\n",
    "loss = sum((U_array[inds,1]-obs[inds,1])^2)\n",
    "sess = Session()\n",
    "init(sess)\n",
    "#u_out = run(sess, U_array)\n",
    "loss_hist = BFGS!(sess, loss, 750)\n",
    "#print(loss_hist)\n",
    "out = run(sess, U_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Optimization starts...\n",
      "└ @ ADCME /home/darve/adncat/.julia/packages/ADCME/OGm7w/src/optim.jl:326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, current loss=471.5271717215378\n",
      "iter 1, current loss=1.8727727458477274e7\n",
      "iter 2, current loss=471.75988977897754\n",
      "iter 3, current loss=471.51123125567636\n",
      "================ STEP 0 ===============\n",
      "iter 4, current loss=471.50357871372\n",
      "================ STEP 1 ===============\n",
      "iter 5, current loss=471.49218760951334\n",
      "================ STEP 2 ===============\n",
      "iter 6, current loss=471.44774845444243\n",
      "================ STEP 3 ===============\n",
      "iter 7, current loss=471.3866401099938\n",
      "================ STEP 4 ===============\n",
      "iter 8, current loss=471.24907488916074\n",
      "================ STEP 5 ===============\n",
      "iter 9, current loss=471.14839047551715\n",
      "================ STEP 6 ===============\n",
      "iter 10, current loss=471.0950690458585\n",
      "================ STEP 7 ===============\n",
      "iter 11, current loss=471.07581085213417\n",
      "================ STEP 8 ===============\n",
      "iter 12, current loss=471.0481269751032\n",
      "================ STEP 9 ===============\n",
      "iter 13, current loss=470.94471781477046\n",
      "================ STEP 10 ===============\n",
      "iter 14, current loss=470.80174800494353\n",
      "================ STEP 11 ===============\n",
      "iter 15, current loss=470.70237848874126\n",
      "================ STEP 12 ===============\n",
      "iter 16, current loss=470.638271763968\n",
      "================ STEP 13 ===============\n",
      "iter 17, current loss=470.60577752695576\n",
      "================ STEP 14 ===============\n",
      "iter 18, current loss=470.5779828631594\n",
      "================ STEP 15 ===============\n",
      "iter 19, current loss=470.52286364217855\n",
      "================ STEP 16 ===============\n",
      "iter 20, current loss=470.319794518221\n",
      "================ STEP 17 ===============\n",
      "iter 21, current loss=469.94136924976976\n",
      "================ STEP 18 ===============\n",
      "iter 22, current loss=469.1242411893945\n",
      "================ STEP 19 ===============\n",
      "iter 23, current loss=468.24563159885804\n",
      "================ STEP 20 ===============\n",
      "iter 24, current loss=467.1179810546688\n",
      "================ STEP 21 ===============\n",
      "iter 25, current loss=466.63247833283543\n",
      "================ STEP 22 ===============\n",
      "iter 26, current loss=466.49638985733776\n",
      "================ STEP 23 ===============\n",
      "iter 27, current loss=466.4707561933385\n",
      "================ STEP 24 ===============\n",
      "iter 28, current loss=466.3500563022609\n",
      "================ STEP 25 ===============\n",
      "iter 29, current loss=465.6332938190149\n",
      "================ STEP 26 ===============\n",
      "iter 30, current loss=465.1650370886851\n",
      "================ STEP 27 ===============\n",
      "iter 31, current loss=464.8419457136756\n",
      "================ STEP 28 ===============\n",
      "iter 32, current loss=464.7273980702262\n",
      "================ STEP 29 ===============\n",
      "iter 33, current loss=464.6805071204851\n",
      "================ STEP 30 ===============\n",
      "iter 34, current loss=464.6560788862819\n",
      "================ STEP 31 ===============\n",
      "iter 35, current loss=464.6222914013638\n",
      "================ STEP 32 ===============\n",
      "iter 36, current loss=464.5312424623092\n",
      "================ STEP 33 ===============\n",
      "iter 37, current loss=464.4001807659285\n",
      "================ STEP 34 ===============\n",
      "iter 38, current loss=466.23280753292886\n",
      "iter 39, current loss=464.35261117489654\n",
      "================ STEP 35 ===============\n",
      "iter 40, current loss=464.1305282716767\n",
      "================ STEP 36 ===============\n",
      "iter 41, current loss=463.8746594576429\n",
      "================ STEP 37 ===============\n",
      "iter 42, current loss=463.6877386059151\n",
      "================ STEP 38 ===============\n",
      "iter 43, current loss=463.5104579196047\n",
      "================ STEP 39 ===============\n",
      "iter 44, current loss=463.24797624255666\n",
      "================ STEP 40 ===============\n",
      "iter 45, current loss=462.46023454775036\n",
      "================ STEP 41 ===============\n",
      "iter 46, current loss=461.54218957538615\n",
      "================ STEP 42 ===============\n",
      "iter 47, current loss=459.8655917444849\n",
      "================ STEP 43 ===============\n",
      "iter 48, current loss=457.5866694002203\n",
      "================ STEP 44 ===============\n",
      "iter 49, current loss=454.73408408821433\n",
      "================ STEP 45 ===============\n",
      "iter 50, current loss=451.9797822992446\n",
      "================ STEP 46 ===============\n",
      "iter 51, current loss=451.54072910365977\n",
      "================ STEP 47 ===============\n",
      "iter 52, current loss=448.4609010448323\n",
      "================ STEP 48 ===============\n",
      "iter 53, current loss=448.2590219703668\n",
      "================ STEP 49 ===============\n",
      "iter 54, current loss=448.14503828037016\n",
      "================ STEP 50 ===============\n",
      "iter 55, current loss=447.9176821203577\n",
      "================ STEP 51 ===============\n",
      "iter 56, current loss=448.8781437731163\n",
      "iter 57, current loss=447.8182039173157\n",
      "================ STEP 52 ===============\n",
      "iter 58, current loss=447.56518476687364\n",
      "================ STEP 53 ===============\n",
      "iter 59, current loss=446.26360258714817\n",
      "================ STEP 54 ===============\n",
      "iter 60, current loss=445.0029756832776\n",
      "================ STEP 55 ===============\n",
      "iter 61, current loss=443.3964844284827\n",
      "================ STEP 56 ===============\n",
      "iter 62, current loss=442.69939536417115\n",
      "================ STEP 57 ===============\n",
      "iter 63, current loss=441.70646738717596\n",
      "================ STEP 58 ===============\n",
      "iter 64, current loss=441.4319142923106\n",
      "================ STEP 59 ===============\n",
      "iter 65, current loss=441.17608864484515\n",
      "================ STEP 60 ===============\n",
      "iter 66, current loss=440.96494513983487\n",
      "================ STEP 61 ===============\n",
      "iter 67, current loss=440.73917169447463\n",
      "================ STEP 62 ===============\n",
      "iter 68, current loss=440.4901234345625\n",
      "================ STEP 63 ===============\n",
      "iter 69, current loss=440.0159461992806\n",
      "================ STEP 64 ===============\n",
      "iter 70, current loss=439.37069127926435\n",
      "================ STEP 65 ===============\n",
      "iter 71, current loss=438.66534213104\n",
      "================ STEP 66 ===============\n",
      "iter 72, current loss=442.5959513141994\n",
      "iter 73, current loss=438.2146897643637\n",
      "================ STEP 67 ===============\n",
      "iter 74, current loss=436.71792673335136\n",
      "================ STEP 68 ===============\n",
      "iter 75, current loss=431.30819449150295\n",
      "================ STEP 69 ===============\n",
      "iter 76, current loss=428.3227387277433\n",
      "================ STEP 70 ===============\n",
      "iter 77, current loss=426.0225357769747\n",
      "================ STEP 71 ===============\n",
      "iter 78, current loss=450.4227097581055\n",
      "iter 79, current loss=424.3371922005967\n",
      "================ STEP 72 ===============\n",
      "iter 80, current loss=421.6182221627488\n",
      "================ STEP 73 ===============\n",
      "iter 81, current loss=420.32411550235827\n",
      "================ STEP 74 ===============\n",
      "iter 82, current loss=420.05913944782884\n",
      "================ STEP 75 ===============\n",
      "iter 83, current loss=419.91892455924403\n",
      "================ STEP 76 ===============\n",
      "iter 84, current loss=419.5588384346513\n",
      "================ STEP 77 ===============\n",
      "iter 85, current loss=419.301600485809\n",
      "================ STEP 78 ===============\n",
      "iter 86, current loss=418.8644760598196\n",
      "================ STEP 79 ===============\n",
      "iter 87, current loss=418.7086000751293\n",
      "================ STEP 80 ===============\n",
      "iter 88, current loss=418.60890160080805\n",
      "================ STEP 81 ===============\n",
      "iter 89, current loss=418.483141503408\n",
      "================ STEP 82 ===============\n",
      "iter 90, current loss=418.4214541262695\n",
      "================ STEP 83 ===============\n",
      "iter 91, current loss=418.32437157969264\n",
      "================ STEP 84 ===============\n",
      "iter 92, current loss=418.20607735379417\n",
      "================ STEP 85 ===============\n",
      "iter 93, current loss=418.6229852152235\n",
      "iter 94, current loss=418.18691041003814\n",
      "================ STEP 86 ===============\n",
      "iter 95, current loss=418.1496799756716\n",
      "================ STEP 87 ===============\n",
      "iter 96, current loss=418.1109759049881\n",
      "================ STEP 88 ===============\n",
      "iter 97, current loss=418.08374037447186\n",
      "================ STEP 89 ===============\n",
      "iter 98, current loss=418.01488893390524\n",
      "================ STEP 90 ===============\n",
      "iter 99, current loss=417.8822619675243\n",
      "================ STEP 91 ===============\n",
      "iter 100, current loss=417.25413784408363\n",
      "================ STEP 92 ===============\n",
      "iter 101, current loss=416.01803315913975\n",
      "================ STEP 93 ===============\n",
      "iter 102, current loss=414.80030973086696\n",
      "================ STEP 94 ===============\n",
      "iter 103, current loss=414.0442883009901\n",
      "iter 104, current loss=412.62754905761847\n",
      "================ STEP 95 ===============\n",
      "iter 105, current loss=409.61474752346567\n",
      "================ STEP 96 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 106, current loss=408.2225502433315\n",
      "================ STEP 97 ===============\n",
      "iter 107, current loss=407.1338494084465\n",
      "================ STEP 98 ===============\n",
      "iter 108, current loss=406.8954699970433\n",
      "================ STEP 99 ===============\n",
      "iter 109, current loss=408.1966754547483\n",
      "iter 110, current loss=406.4232595263354\n",
      "================ STEP 100 ===============\n",
      "iter 111, current loss=406.0039269746794\n",
      "================ STEP 101 ===============\n",
      "iter 112, current loss=403.8673816688836\n",
      "================ STEP 102 ===============\n",
      "iter 113, current loss=402.5829395590048\n",
      "================ STEP 103 ===============\n",
      "iter 114, current loss=400.24549097216584\n",
      "================ STEP 104 ===============\n",
      "iter 115, current loss=397.8147852103431\n",
      "================ STEP 105 ===============\n",
      "iter 116, current loss=396.78069737505444\n",
      "================ STEP 106 ===============\n",
      "iter 117, current loss=394.4895911118918\n",
      "================ STEP 107 ===============\n",
      "iter 118, current loss=392.85563185601126\n",
      "================ STEP 108 ===============\n",
      "iter 119, current loss=391.47454605666553\n",
      "================ STEP 109 ===============\n",
      "iter 120, current loss=387.4926426473662\n",
      "================ STEP 110 ===============\n",
      "iter 121, current loss=387.2505141175888\n",
      "================ STEP 111 ===============\n",
      "iter 122, current loss=385.4482209747485\n",
      "================ STEP 112 ===============\n",
      "iter 123, current loss=384.73263468876814\n",
      "================ STEP 113 ===============\n",
      "iter 124, current loss=384.22776131526984\n",
      "================ STEP 114 ===============\n",
      "iter 125, current loss=384.0190980285295\n",
      "================ STEP 115 ===============\n",
      "iter 126, current loss=383.32850723864317\n",
      "================ STEP 116 ===============\n",
      "iter 127, current loss=383.15353139179\n",
      "================ STEP 117 ===============\n",
      "iter 128, current loss=382.78533128187144\n",
      "================ STEP 118 ===============\n",
      "iter 129, current loss=382.40391919947683\n",
      "================ STEP 119 ===============\n",
      "iter 130, current loss=381.87590068818264\n",
      "================ STEP 120 ===============\n",
      "iter 131, current loss=383.69964012773175\n",
      "iter 132, current loss=381.3462199373258\n",
      "================ STEP 121 ===============\n",
      "iter 133, current loss=380.4799923357746\n",
      "================ STEP 122 ===============\n",
      "iter 134, current loss=379.0850125800415\n",
      "================ STEP 123 ===============\n",
      "iter 135, current loss=378.402337806755\n",
      "================ STEP 124 ===============\n",
      "iter 136, current loss=377.3404056800845\n",
      "================ STEP 125 ===============\n",
      "iter 137, current loss=377.32749911525286\n",
      "iter 138, current loss=376.9275626558169\n",
      "================ STEP 126 ===============\n",
      "iter 139, current loss=376.5120338997185\n",
      "================ STEP 127 ===============\n",
      "iter 140, current loss=375.6012440614981\n",
      "================ STEP 128 ===============\n",
      "iter 141, current loss=374.42920435711494\n",
      "================ STEP 129 ===============\n",
      "iter 142, current loss=372.2021483797061\n",
      "================ STEP 130 ===============\n",
      "iter 143, current loss=369.42946870384924\n",
      "================ STEP 131 ===============\n",
      "iter 144, current loss=366.5871830279896\n",
      "================ STEP 132 ===============\n",
      "iter 145, current loss=364.1679791198859\n",
      "================ STEP 133 ===============\n",
      "iter 146, current loss=360.8986276381604\n",
      "================ STEP 134 ===============\n",
      "iter 147, current loss=357.1297842505719\n",
      "================ STEP 135 ===============\n",
      "iter 148, current loss=353.8185729537446\n",
      "================ STEP 136 ===============\n",
      "iter 149, current loss=351.35626104108655\n",
      "================ STEP 137 ===============\n",
      "iter 150, current loss=349.3319561848482\n",
      "================ STEP 138 ===============\n",
      "iter 151, current loss=348.17230103069096\n",
      "================ STEP 139 ===============\n",
      "iter 152, current loss=346.1762432271823\n",
      "================ STEP 140 ===============\n",
      "iter 153, current loss=345.35968901506203\n",
      "================ STEP 141 ===============\n",
      "iter 154, current loss=357.3357384709091\n",
      "iter 155, current loss=344.7798257005564\n",
      "================ STEP 142 ===============\n",
      "iter 156, current loss=343.8415608345801\n",
      "================ STEP 143 ===============\n",
      "iter 157, current loss=343.5019960987912\n",
      "================ STEP 144 ===============\n",
      "iter 158, current loss=342.7701885295231\n",
      "================ STEP 145 ===============\n",
      "iter 159, current loss=342.02978178805824\n",
      "================ STEP 146 ===============\n",
      "iter 160, current loss=341.49547251303045\n",
      "================ STEP 147 ===============\n",
      "iter 161, current loss=340.847205785053\n",
      "================ STEP 148 ===============\n",
      "iter 162, current loss=340.5442948365253\n",
      "================ STEP 149 ===============\n",
      "iter 163, current loss=340.4386055350425\n",
      "================ STEP 150 ===============\n",
      "iter 164, current loss=340.218940282399\n",
      "================ STEP 151 ===============\n",
      "iter 165, current loss=340.05590986222427\n",
      "================ STEP 152 ===============\n",
      "iter 166, current loss=339.94207586642375\n",
      "================ STEP 153 ===============\n",
      "iter 167, current loss=339.7820516511589\n",
      "================ STEP 154 ===============\n",
      "iter 168, current loss=339.64958557512654\n",
      "================ STEP 155 ===============\n",
      "iter 169, current loss=339.5261749685843\n",
      "================ STEP 156 ===============\n",
      "iter 170, current loss=340.3188565038878\n",
      "iter 171, current loss=339.45759057226655\n",
      "================ STEP 157 ===============\n",
      "iter 172, current loss=339.3337058171528\n",
      "================ STEP 158 ===============\n",
      "iter 173, current loss=338.4391253968679\n",
      "================ STEP 159 ===============\n",
      "iter 174, current loss=337.57388908224146\n",
      "================ STEP 160 ===============\n",
      "iter 175, current loss=336.8300828911029\n",
      "================ STEP 161 ===============\n",
      "iter 176, current loss=336.4011504954527\n",
      "================ STEP 162 ===============\n",
      "iter 177, current loss=336.408726565597\n",
      "iter 178, current loss=336.18617177277\n",
      "================ STEP 163 ===============\n",
      "iter 179, current loss=335.9359038337037\n",
      "================ STEP 164 ===============\n",
      "iter 180, current loss=335.69496018256143\n",
      "================ STEP 165 ===============\n",
      "iter 181, current loss=335.14389955117974\n",
      "================ STEP 166 ===============\n",
      "iter 182, current loss=333.8169092536412\n",
      "================ STEP 167 ===============\n",
      "iter 183, current loss=332.7761214839405\n",
      "================ STEP 168 ===============\n",
      "iter 184, current loss=331.9681805517211\n",
      "================ STEP 169 ===============\n",
      "iter 185, current loss=331.21983033654357\n",
      "================ STEP 170 ===============\n",
      "iter 186, current loss=330.53600228323916\n",
      "================ STEP 171 ===============\n",
      "iter 187, current loss=328.98822998819554\n",
      "================ STEP 172 ===============\n",
      "iter 188, current loss=328.4270078895713\n",
      "================ STEP 173 ===============\n",
      "iter 189, current loss=325.79150017198214\n",
      "================ STEP 174 ===============\n",
      "iter 190, current loss=324.0404080258808\n",
      "================ STEP 175 ===============\n",
      "iter 191, current loss=323.12975561354847\n",
      "================ STEP 176 ===============\n",
      "iter 192, current loss=322.7513584470173\n",
      "================ STEP 177 ===============\n",
      "iter 193, current loss=322.1259592148241\n",
      "================ STEP 178 ===============\n",
      "iter 194, current loss=319.8501533760091\n",
      "================ STEP 179 ===============\n",
      "iter 195, current loss=318.32240636854874\n",
      "================ STEP 180 ===============\n",
      "iter 196, current loss=317.10192886035566\n",
      "================ STEP 181 ===============\n",
      "iter 197, current loss=316.72945743306684\n",
      "================ STEP 182 ===============\n",
      "iter 198, current loss=316.4425101583346\n",
      "================ STEP 183 ===============\n",
      "iter 199, current loss=320.2006868850724\n",
      "iter 200, current loss=315.6844838510054\n",
      "================ STEP 184 ===============\n",
      "iter 201, current loss=314.3778128887091\n",
      "================ STEP 185 ===============\n",
      "iter 202, current loss=312.45762553147193\n",
      "================ STEP 186 ===============\n",
      "iter 203, current loss=311.31547086673726\n",
      "================ STEP 187 ===============\n",
      "iter 204, current loss=310.8162107473781\n",
      "================ STEP 188 ===============\n",
      "iter 205, current loss=310.50025287774713\n",
      "================ STEP 189 ===============\n",
      "iter 206, current loss=310.2849588057927\n",
      "================ STEP 190 ===============\n",
      "iter 207, current loss=309.0003315438597\n",
      "================ STEP 191 ===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 208, current loss=306.9480688029805\n",
      "================ STEP 192 ===============\n",
      "iter 209, current loss=302.4300173370096\n",
      "================ STEP 193 ===============\n",
      "iter 210, current loss=305.7218167058582\n",
      "iter 211, current loss=300.5811713047591\n",
      "================ STEP 194 ===============\n",
      "iter 212, current loss=297.8096571219171\n",
      "================ STEP 195 ===============\n",
      "iter 213, current loss=347.33123528836137\n",
      "iter 214, current loss=297.13499040979406\n",
      "================ STEP 196 ===============\n",
      "iter 215, current loss=296.51037833329417\n",
      "================ STEP 197 ===============\n",
      "iter 216, current loss=294.8670467269279\n",
      "================ STEP 198 ===============\n",
      "iter 217, current loss=297.93072354019773\n",
      "iter 218, current loss=294.68184711977835\n",
      "================ STEP 199 ===============\n",
      "iter 219, current loss=294.35445959078146\n",
      "================ STEP 200 ===============\n",
      "iter 220, current loss=294.0095996251415\n",
      "================ STEP 201 ===============\n",
      "iter 221, current loss=293.6904658108267\n",
      "================ STEP 202 ===============\n",
      "iter 222, current loss=293.5079307872943\n",
      "================ STEP 203 ===============\n",
      "iter 223, current loss=294.5119712951372\n",
      "iter 224, current loss=293.365783324326\n",
      "================ STEP 204 ===============\n",
      "iter 225, current loss=293.25190063823595\n",
      "================ STEP 205 ===============\n",
      "iter 226, current loss=293.2072603051724\n",
      "================ STEP 206 ===============\n",
      "iter 227, current loss=293.12262987119846\n",
      "================ STEP 207 ===============\n",
      "iter 228, current loss=292.9383231734013\n",
      "================ STEP 208 ===============\n",
      "iter 229, current loss=292.70633945664724\n",
      "================ STEP 209 ===============\n",
      "iter 230, current loss=292.5521648859132\n",
      "================ STEP 210 ===============\n",
      "iter 231, current loss=292.47266424668396\n",
      "================ STEP 211 ===============\n",
      "iter 232, current loss=292.8735990078536\n",
      "iter 233, current loss=292.4104272885072\n",
      "================ STEP 212 ===============\n",
      "iter 234, current loss=292.3734473962808\n",
      "================ STEP 213 ===============\n",
      "iter 235, current loss=292.36744481725856\n",
      "================ STEP 214 ===============\n",
      "iter 236, current loss=292.36554063442793\n",
      "================ STEP 215 ===============\n",
      "iter 237, current loss=292.3609529001918\n",
      "================ STEP 216 ===============\n",
      "iter 238, current loss=292.3542107427837\n",
      "================ STEP 217 ===============\n",
      "iter 239, current loss=292.34171939378416\n",
      "================ STEP 218 ===============\n",
      "iter 240, current loss=292.3187524684116\n",
      "================ STEP 219 ===============\n",
      "iter 241, current loss=292.3219597614978\n",
      "iter 242, current loss=292.3015868261144\n",
      "================ STEP 220 ===============\n",
      "iter 243, current loss=292.28808791277777\n",
      "================ STEP 221 ===============\n",
      "iter 244, current loss=292.26285783070875\n",
      "================ STEP 222 ===============\n",
      "iter 245, current loss=292.2371203495021\n",
      "================ STEP 223 ===============\n",
      "iter 246, current loss=292.93008731919366\n",
      "iter 247, current loss=292.20678072522855\n",
      "================ STEP 224 ===============\n",
      "iter 248, current loss=292.17155847686865\n",
      "================ STEP 225 ===============\n",
      "iter 249, current loss=292.11961412906254\n",
      "================ STEP 226 ===============\n",
      "iter 250, current loss=292.33697013918385\n",
      "iter 251, current loss=291.97440986054403\n",
      "================ STEP 227 ===============\n",
      "iter 252, current loss=291.6888663747326\n",
      "================ STEP 228 ===============\n",
      "iter 253, current loss=291.3601809282495\n",
      "================ STEP 229 ===============\n",
      "iter 254, current loss=291.2973053042645\n",
      "================ STEP 230 ===============\n",
      "iter 255, current loss=291.2725224848351\n",
      "================ STEP 231 ===============\n",
      "iter 256, current loss=291.2821747030611\n",
      "iter 257, current loss=291.2611594760533\n",
      "================ STEP 232 ===============\n",
      "iter 258, current loss=291.24961116080783\n",
      "================ STEP 233 ===============\n",
      "iter 259, current loss=291.2242277059377\n",
      "================ STEP 234 ===============\n",
      "iter 260, current loss=291.2241010713933\n",
      "================ STEP 235 ===============\n",
      "iter 261, current loss=291.21236741175267\n",
      "================ STEP 236 ===============\n",
      "iter 262, current loss=291.17923667447667\n",
      "================ STEP 237 ===============\n",
      "iter 263, current loss=291.1215016392189\n",
      "================ STEP 238 ===============\n",
      "iter 264, current loss=291.054952492531\n",
      "================ STEP 239 ===============\n",
      "iter 265, current loss=291.03405059496373\n",
      "================ STEP 240 ===============\n",
      "iter 266, current loss=290.99610822778254\n",
      "================ STEP 241 ===============\n",
      "iter 267, current loss=290.87534786089833\n",
      "================ STEP 242 ===============\n",
      "iter 268, current loss=290.72164273985396\n",
      "================ STEP 243 ===============\n",
      "iter 269, current loss=290.3441041455093\n",
      "================ STEP 244 ===============\n",
      "iter 270, current loss=289.9763612666881\n",
      "================ STEP 245 ===============\n",
      "iter 271, current loss=289.7289876137967\n",
      "================ STEP 246 ===============\n",
      "iter 272, current loss=289.550097931315\n",
      "================ STEP 247 ===============\n",
      "iter 273, current loss=289.40751045192695\n",
      "================ STEP 248 ===============\n",
      "iter 274, current loss=289.3332231535807\n",
      "================ STEP 249 ===============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250-element Array{Any,1}:\n",
       " 471.51123125567636\n",
       " 471.50357871372\n",
       " 471.49218760951334\n",
       " 471.44774845444243\n",
       " 471.3866401099938\n",
       " 471.24907488916074\n",
       " 471.14839047551715\n",
       " 471.0950690458585\n",
       " 471.07581085213417\n",
       " 471.0481269751032\n",
       " 470.94471781477046\n",
       " 470.80174800494353\n",
       " 470.70237848874126\n",
       "   ⋮\n",
       " 291.1215016392189\n",
       " 291.054952492531\n",
       " 291.03405059496373\n",
       " 290.99610822778254\n",
       " 290.87534786089833\n",
       " 290.72164273985396\n",
       " 290.3441041455093\n",
       " 289.9763612666881\n",
       " 289.7289876137967\n",
       " 289.550097931315\n",
       " 289.40751045192695\n",
       " 289.3332231535807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_hist2 = BFGS!(sess, loss, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### nt = size(timestep)[1]\n",
    "TY = [T; Y]\n",
    "function condition(k, U, t, θ)\n",
    "    k <= nt - 1\n",
    "end\n",
    "\n",
    "function body(k, U, t, θ)\n",
    "    dt = t[k + 1] - t[k]\n",
    "    uk = read(U,k)\n",
    "    k1 = f(uk, θ)\n",
    "    k2 = f(uk + 0.5 * dt * k1, θ)\n",
    "    k3 = f(uk + 0.5 * dt * k2, θ)\n",
    "    k4 = f(uk + dt * k3, θ) \n",
    "    u_new = uk + 1/6 * dt * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "    U = write(U, k+1, u_new)\n",
    "    k+1, U, t, θ\n",
    "end\n",
    "k = constant(1, dtype=Int32)\n",
    "t = constant(timestep)\n",
    "θ = Variable(pr)\n",
    "U = TensorArray(nt)\n",
    "U = write(U, 1, TY)\n",
    "_, U_out=while_loop(condition, body, [k, U, t, θ])\n",
    "U_array = set_shape(stack(U_out), (nt, N+1))\n",
    "sess = Session()\n",
    "init(sess)\n",
    "u_out = run(sess, U_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dt = 1e-6\n",
    "nt = size(timestep[1:1000])[1]\n",
    "#### Implicit scheme, need to refine for variable time step and order\n",
    "function res_and_jac(param, x)\n",
    "    dt = param[1]\n",
    "    x0 = param[2:end]\n",
    "    res = x - x0 - dt * f(x)\n",
    "    jac = gradients(res, x)\n",
    "    res, jac \n",
    "end\n",
    "\n",
    "function condition(k, U, t)\n",
    "    k <= nt - 1\n",
    "end\n",
    "\n",
    "function body(k, U, t)\n",
    "    dt = t[k + 1] - t[k]\n",
    "    uk = read(U,k)\n",
    "    ADCME.options.newton_raphson.rtol = 1e-5 # relative tolerance\n",
    "    ADCME.options.newton_raphson.tol = 1e-5 # absolute tolerance\n",
    "    ADCME.options.newton_raphson.verbose = true # print details in newton_raphson\n",
    "    param = tf.concat([tf.reshape(dt, (1,)), uk], 0)\n",
    "    u_new = newton_raphson_with_grad(res_and_jac, constant(uk), param)\n",
    "    U = write(U, k+1, u_new)\n",
    "    k+1, U, t\n",
    "end\n",
    "\n",
    "k = constant(1, dtype=Int32)\n",
    "t = constant(timestep)\n",
    "U = TensorArray(nt)\n",
    "U = write(U, 1, TY)\n",
    "_, U_out=while_loop(condition, body, [k, U, t])\n",
    "U_array = set_shape(stack(U_out), (nt, N+1))\n",
    "sess = Session()\n",
    "init(sess)\n",
    "u_out = run(sess, U_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inds = range(1,2000, step=100)\n",
    "plot(timestep[inds], Y_ref'[inds,:], seriestype = :scatter, legend = false)\n",
    "plot!(timestep, u_out[:,2:end])\n",
    "xlabel!(\"Time\")\n",
    "ylabel!(\"Mass Fractions\")\n",
    "savefig(\"Mass_fraction.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inds = range(1,2000, step=400)\n",
    "plot(timestep[inds], T_ref[inds], seriestype = :scatter, label = \"observation\")\n",
    "plot!(timestep[2:end], Tt_cant, label = \"true\")\n",
    "plot!(timestep, out[:,1], label = \"predicted\")\n",
    "xlabel!(\"Time\")\n",
    "ylabel!(\"Temperature\")\n",
    "savefig(\"temperature_3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1e-6\n",
    "u1 = constant(TY)\n",
    "function res_and_jac(x0, x)\n",
    "    res = x - x0 - dt * f(x)\n",
    "    jac = gradients(res, x)\n",
    "    res, jac \n",
    "end\n",
    "ADCME.options.newton_raphson.rtol = 1e-4 # relative tolerance\n",
    "ADCME.options.newton_raphson.tol = 1e-4 # absolute tolerance\n",
    "ADCME.options.newton_raphson.verbose = true # print details in newton_raphson\n",
    "u_est = newton_raphson_with_grad(res_and_jac, constant(u1), u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = Session()\n",
    "init(sess)\n",
    "u_e = run(sess, u_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28.3244  0.0  18.8021\n",
    " 17.9616  0.0  17.7315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out[range(1,2000, step=100),2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = [log.(Afr) βr log.(Er)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(log.(loss), label=\"log of mse\")\n",
    "xlabel!(\"steps\")\n",
    "ylabel!(\"logarithm of loss\")\n",
    "savefig(\"loss.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = Variable(fc_init([1,20,20,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = Variable(0.5)\n",
    "fc(XX, [20,20,1], θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = Variable(TY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(ty, θ, constant(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tout_g = q.(timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tout = fc(timestep, [20,20,1], θ)\n",
    "loss = sum((tout - tout_g)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#θ = Variable(fc_init([1,20,20,1]))\n",
    "#C = Variable(11.0)\n",
    "tout = fc(timestep * 1e5, [20,20,1], θ; activation = \"tanh\")\n",
    "pred = tout * 10 ^ C\n",
    "#loss = sum((pred - tout_g)^2) \n",
    "#sess = Session()\n",
    "#init(sess)\n",
    "#u_out = run(sess, U_array)\n",
    "#loss_hist = BFGS!(sess, loss)\n",
    "tout = run(sess, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot(timestep, tout_g)\n",
    "plot(timestep, tout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-element Array{Float64,1}:\n",
       " 3.7200759760208887e-32\n",
       " 3.7208200652505616e-32\n",
       " 3.7223086880040565e-32\n",
       " 3.7245427333101807e-32\n",
       " 3.727523535812236e-32\n",
       " 3.731252877090545e-32\n",
       " 3.7357329874283037e-32\n",
       " 3.7409665480229064e-32\n",
       " 3.746956693647616e-32\n",
       " 3.753707015764383e-32\n",
       " 3.761221566095272e-32\n",
       " 3.769504860654328e-32\n",
       " 3.778561884248479e-32\n",
       " ⋮\n",
       " 2.348330389857639e-30\n",
       " 1.5898579986997044e-30\n",
       " 1.0752962189675263e-30\n",
       " 7.265542158660972e-31\n",
       " 4.904305803407465e-31\n",
       " 3.30716714742584e-31\n",
       " 2.227939102192905e-31\n",
       " 1.4994035491696873e-31\n",
       " 1.008094583257523e-31\n",
       " 6.770972273722614e-32\n",
       " 4.543256709289263e-32\n",
       " 3.045436046522662e-32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function q(t)\n",
    "    t0 = 1\n",
    "    r = 0.1\n",
    "    c = 1e12\n",
    "    return c * exp(-(t-t0)^2 / r^2)\n",
    "end\n",
    "tout_g = q.(timestep * 1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_C = run(sess, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_theta = run(sess, θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(sess, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(sess, θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc(timestep * 1e5, [20,20,1], θ; activation = \"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = Variable(TY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc(t * 1e5, [20,20,1], temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Variable(fc_init([1,20,20,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[C, θ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc(t * 1e5, [20,20,1], theta[2]; activation = \"tanh\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = constant(0.01)\n",
    "T = ty[1]\n",
    "Y = ty[2:end]\n",
    "ρ = m / V # density\n",
    "X = tf.reshape(ρ * tf.divide(Y, W), (N,1)) # Concentration\n",
    "Q = ADCME.constant(ones(M)) # Individual progress rates\n",
    "islarge = T > ADCME.constant(NASA_coeffs[:,1])\n",
    "islarge = convert_to_tensor(islarge, dtype=Float64)\n",
    "fhi = f_hi(NASA_coeffs, T, R)\n",
    "flo = f_lo(NASA_coeffs, T, R)\n",
    "cp = islarge .* fhi[:,1] + (1 - islarge) .* flo[:,1]\n",
    "h = islarge .* fhi[:,2] + (1 - islarge) .* flo[:,2]\n",
    "s = islarge .* fhi[:,3] + (1 - islarge) .* flo[:,3]\n",
    "cvk = cp .- R\n",
    "ΔS = ν' * s  # Entropy change for reaction j\n",
    "ΔH = ν' * h # Entahlpy change for reaction j\n",
    "####\n",
    "M_t = efficiency_t' * X[:,1]\n",
    "Kf_t = Af_t .* (T ^ β_t) .* exp(-E_t / (R * T)) .* M_t\n",
    "Kr_t = Kf_t ./ (((pa/(R * T)) ^ sum(ν[:,tbd], dims=1)')[:,1] .* exp(ΔS[tbd] ./ R - ΔH[tbd] / (R * T)))\n",
    "Qtbd =  Kf_t .* (prod(tf.pow(X, order_t), dims=1)) .- Kr_t .* (prod(tf.pow(X, ν2[:,tbd]), dims=1) .* reversible[tbd])\n",
    "M_f = efficiency_f' * X[:,1]\n",
    "Kf_lo = Af_lo .* (T ^ β_lo) .* exp(-E_lo / (R * T)) .* M_f\n",
    "Kf_hi = Af_hi .* (T ^ β_hi) .* exp(-E_hi / (R * T)) \n",
    "Pr = Kf_lo ./ Kf_hi\n",
    "Fac = ADCME.constant(ones(size(falofr)[1]))\n",
    "for (i,s) in enumerate(troefall)\n",
    "    a = troefall_coeff[:,i]\n",
    "    fcent = (1 - a[1]) * exp(-T/a[2]) + a[1] * exp(-T/a[3]) + exp(-a[4]/T)\n",
    "    c = -0.4 - 0.67 * log(fcent) / log(10)\n",
    "    n = 0.75 - 1.27 * log(fcent) / log(10)\n",
    "    f1 = (log(Pr[s]) / log(10) + c) / (n - 0.14 *(log(Pr[s]) / log(10) + c))\n",
    "    Fac = scatter_update(Fac, troefall[i], 10 ^ ((log(fcent) / log(10)) / (1 + f1 ^ 2)))\n",
    "end\n",
    "Kf_f = Kf_lo ./ (1 .+ (Kf_lo ./ Kf_hi)) .* Fac\n",
    "Kr_f = Kf_f ./ (((pa/(R * T)) ^ sum(ν[:,falofr], dims=1)')[:,1] .* exp(ΔS[falofr] ./ R - ΔH[falofr] / (R * T)))\n",
    "Qfalofr = Kf_f .* (prod(tf.pow(X, order_f), dims=1)) .- Kr_f .* (prod(tf.pow(X, ν2[:,falofr]), dims=1) .* reversible[falofr])\n",
    "####\n",
    "#     Af = exp(θ[:,1])\n",
    "#     β = zeros(M)\n",
    "#     E = exp(θ[:,3])\n",
    "Kf = Af .* (T ^ β) .* exp(-E / (R * T))\n",
    "Kr = Kf ./ (((pa/(R * T)) ^ sum(ν[:,elmr], dims=1)')[:,1] .* exp(ΔS[elmr] ./ R - ΔH[elmr] / (R * T)))\n",
    "Qelmr = Kf .* (prod(tf.pow(X, order), dims=1)) .- Kr .* (prod(tf.pow(X, ν2[:,elmr]), dims=1) .* reversible[elmr])\n",
    "Q = [Qtbd' Qfalofr' Qelmr']\n",
    "ν_new = [ν[:,tbd] ν[:,falofr] ν[:,elmr]]\n",
    "##### Computing ω_dot \n",
    "cv = sum(cvk ./ W .* Y) # Mass heat capacities\n",
    "u = h / W - R ./ W * T   # Internal energy for species\n",
    "p = sum(X) * R * T # pressure\n",
    "ω_dot = W .* sum(ν_new .* Q, dims=2)\n",
    "###### Species Conservation\n",
    "mgen_dot = V * ω_dot\n",
    "Y_dot = (1 / m) * ((min_dot * (Yin - Y) - mout_dot * Y) + mgen_dot) \n",
    "###### EnergyConservation\n",
    "Qdot = fc(t * 1e5, [20,20,1], θ) \n",
    "T_dot = 1 / (m * cv) * (Qdot + min_dot * (hin - sum(u .* Yin)) - p * V / m * mout_dot - sum(mgen_dot .* u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tout = fc(timestep * 1e5, [20,20,1], θ; activation = \"tanh\")\n",
    "pred = tout * 10 ^ C\n",
    "out = run(sess, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run(sess, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(sess, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((u_out[inds,1]-obs[inds,1]).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = sum((U_array[inds,1]-obs[inds,1])^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tt_cant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out = run(sess, U_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(sess, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variable([0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(log.(loss_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax(Tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep[argmax(Tt[1:20000])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_heat = 0\n",
    "for i = 1:nt-1\n",
    "    dt = timestep[i+1] - timestep[i]\n",
    "    total_heat += dt * q(timestep[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = Variable(fc_init([1,20,20,1]))\n",
    "#C = Variable(1.0)\n",
    "#theta = Variable([8.0, 0.8])\n",
    "Qdtb = fc(t * 1e5, [20,20,1], θ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Qdtb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = t[2:end] - t[1:end-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Qdtb[1:end-1] * (t[2:end] - t[1:end-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-element Array{Float64,1}:\n",
       " 4.698905719255907e8\n",
       " 4.6985093654704016e8\n",
       " 4.6977166938196117e8\n",
       " 4.696527776132711e8\n",
       " 4.6949427201693803e8\n",
       " 4.692961669589928e8\n",
       " 4.690584803993005e8\n",
       " 4.68781233887985e8\n",
       " 4.6846445256792694e8\n",
       " 4.681081651743228e8\n",
       " 4.6771240403424424e8\n",
       " 4.672772050680586e8\n",
       " 4.6680260778648967e8\n",
       " ⋮\n",
       " 1.259904077679363e10\n",
       " 1.266829638586406e10\n",
       " 1.2737630979728926e10\n",
       " 1.2807043767034134e10\n",
       " 1.2876533952951967e10\n",
       " 1.2946100739224539e10\n",
       " 1.301574332420866e10\n",
       " 1.3085460902918314e10\n",
       " 1.3155252667070118e10\n",
       " 1.322511780512863e10\n",
       " 1.3295055502352098e10\n",
       " 1.3365064940837793e10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qdot_out = run(sess, Qdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(timestep, Qdot_out, label=\"Neural Network\")\n",
    "plot!(timestep, tout_g, label=\"Gaussian Heat Source\")\n",
    "xlabel!(\"Time (s)\")\n",
    "ylabel!(\"Heat Flux (J)\")\n",
    "savefig(\"heat_source_3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([loss_hist; loss_hist2], yaxis=:log, label = \"BFGS\")\n",
    "xlabel!(\"steps\")\n",
    "ylabel!(\"loss\")\n",
    "savefig(\"loss_3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot((Qdot_out .- tout_g) ./ maximum(tout_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tout_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = Variable(TY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(ty, Qdot, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "ENV[\"GPU\"] = 0\n",
    "Pkg.build(\"ADCME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ADCME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run(sess, U_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
